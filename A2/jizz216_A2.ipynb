{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f12d5f-87cd-4a12-9065-48b9145c9fd9",
   "metadata": {},
   "source": [
    "TASK 1\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4856e663-b137-4f47-9955-c74879887e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet \"scikit-learn>=0.23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3de1cf-32a3-460b-a894-88c75c703163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075d8a2e-3a20-4f5d-943e-3a6e2cc00b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autorank import autorank, create_report, plot_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97a60bc5-4d05-4592-ae86-f8826a523ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.176595</td>\n",
       "      <td>-4.126644</td>\n",
       "      <td>-2.390884</td>\n",
       "      <td>-1.366659</td>\n",
       "      <td>-0.460177</td>\n",
       "      <td>1.521421</td>\n",
       "      <td>5.328470</td>\n",
       "      <td>-2.919639</td>\n",
       "      <td>-6.216557</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.919015</td>\n",
       "      <td>-1.603442</td>\n",
       "      <td>-0.867395</td>\n",
       "      <td>-1.825951</td>\n",
       "      <td>-2.390884</td>\n",
       "      <td>4.107535</td>\n",
       "      <td>3.817897</td>\n",
       "      <td>-0.823303</td>\n",
       "      <td>-5.271267</td>\n",
       "      <td>2.353398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.267386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.820798</td>\n",
       "      <td>1.540020</td>\n",
       "      <td>1.656770</td>\n",
       "      <td>0.447912</td>\n",
       "      <td>6.484100</td>\n",
       "      <td>2.356129</td>\n",
       "      <td>-1.129611</td>\n",
       "      <td>3.195601</td>\n",
       "      <td>...</td>\n",
       "      <td>1.394421</td>\n",
       "      <td>-1.872976</td>\n",
       "      <td>-0.382098</td>\n",
       "      <td>-1.980864</td>\n",
       "      <td>1.540020</td>\n",
       "      <td>-1.267888</td>\n",
       "      <td>-1.843256</td>\n",
       "      <td>1.105676</td>\n",
       "      <td>-0.344550</td>\n",
       "      <td>-6.653773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.946515</td>\n",
       "      <td>-1.594067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403844</td>\n",
       "      <td>-1.733342</td>\n",
       "      <td>0.274193</td>\n",
       "      <td>2.960081</td>\n",
       "      <td>0.326221</td>\n",
       "      <td>0.393324</td>\n",
       "      <td>0.229915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290845</td>\n",
       "      <td>-0.076589</td>\n",
       "      <td>-4.660688</td>\n",
       "      <td>-1.652196</td>\n",
       "      <td>0.403844</td>\n",
       "      <td>-4.317565</td>\n",
       "      <td>-2.506476</td>\n",
       "      <td>3.422634</td>\n",
       "      <td>-0.272146</td>\n",
       "      <td>-3.345401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.581082</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>1.197022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.416290</td>\n",
       "      <td>-1.941236</td>\n",
       "      <td>0.290991</td>\n",
       "      <td>0.507716</td>\n",
       "      <td>-0.397205</td>\n",
       "      <td>4.399152</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046033</td>\n",
       "      <td>-4.498888</td>\n",
       "      <td>7.150844</td>\n",
       "      <td>0.722794</td>\n",
       "      <td>-2.944502</td>\n",
       "      <td>-0.081950</td>\n",
       "      <td>0.186089</td>\n",
       "      <td>-7.066950</td>\n",
       "      <td>2.488842</td>\n",
       "      <td>-2.770303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.123360</td>\n",
       "      <td>-0.266587</td>\n",
       "      <td>1.781999</td>\n",
       "      <td>-0.039342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895856</td>\n",
       "      <td>3.756880</td>\n",
       "      <td>-4.583167</td>\n",
       "      <td>1.652762</td>\n",
       "      <td>7.673453</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371734</td>\n",
       "      <td>4.458045</td>\n",
       "      <td>3.576609</td>\n",
       "      <td>-1.538929</td>\n",
       "      <td>-0.039342</td>\n",
       "      <td>-2.613114</td>\n",
       "      <td>-3.117484</td>\n",
       "      <td>-2.125028</td>\n",
       "      <td>0.143158</td>\n",
       "      <td>-8.249535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.318539</td>\n",
       "      <td>0.539550</td>\n",
       "      <td>-0.144831</td>\n",
       "      <td>1.402720</td>\n",
       "      <td>2.018928</td>\n",
       "      <td>-0.033435</td>\n",
       "      <td>-0.763604</td>\n",
       "      <td>-4.475018</td>\n",
       "      <td>1.098775</td>\n",
       "      <td>2.187650</td>\n",
       "      <td>...</td>\n",
       "      <td>1.163138</td>\n",
       "      <td>1.427695</td>\n",
       "      <td>0.753621</td>\n",
       "      <td>0.467884</td>\n",
       "      <td>1.402720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.008609</td>\n",
       "      <td>0.279494</td>\n",
       "      <td>4.702728</td>\n",
       "      <td>-2.272688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-5.843779</td>\n",
       "      <td>0.341371</td>\n",
       "      <td>-0.612153</td>\n",
       "      <td>-0.209380</td>\n",
       "      <td>-1.398469</td>\n",
       "      <td>0.550250</td>\n",
       "      <td>-1.623379</td>\n",
       "      <td>-0.924526</td>\n",
       "      <td>-2.274803</td>\n",
       "      <td>-3.090194</td>\n",
       "      <td>...</td>\n",
       "      <td>1.998539</td>\n",
       "      <td>-0.695267</td>\n",
       "      <td>1.238735</td>\n",
       "      <td>1.192938</td>\n",
       "      <td>-0.209380</td>\n",
       "      <td>-0.972033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.624541</td>\n",
       "      <td>0.013214</td>\n",
       "      <td>1.422758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3.406411</td>\n",
       "      <td>0.321762</td>\n",
       "      <td>0.286231</td>\n",
       "      <td>2.116516</td>\n",
       "      <td>-1.548059</td>\n",
       "      <td>-1.626494</td>\n",
       "      <td>3.787104</td>\n",
       "      <td>2.476920</td>\n",
       "      <td>-2.113878</td>\n",
       "      <td>-7.427621</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.762413</td>\n",
       "      <td>-2.860776</td>\n",
       "      <td>-6.281361</td>\n",
       "      <td>-3.061634</td>\n",
       "      <td>2.116516</td>\n",
       "      <td>6.246774</td>\n",
       "      <td>-0.847790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.109827</td>\n",
       "      <td>2.108502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-2.167186</td>\n",
       "      <td>0.627939</td>\n",
       "      <td>-0.993588</td>\n",
       "      <td>0.902711</td>\n",
       "      <td>-1.024744</td>\n",
       "      <td>-0.416702</td>\n",
       "      <td>3.966772</td>\n",
       "      <td>6.068817</td>\n",
       "      <td>-2.394340</td>\n",
       "      <td>-1.352014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.981470</td>\n",
       "      <td>-2.427518</td>\n",
       "      <td>-0.065137</td>\n",
       "      <td>-1.653230</td>\n",
       "      <td>0.902711</td>\n",
       "      <td>1.644251</td>\n",
       "      <td>-0.421722</td>\n",
       "      <td>-3.231510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.626739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-3.621659</td>\n",
       "      <td>-1.628561</td>\n",
       "      <td>-1.991653</td>\n",
       "      <td>3.852027</td>\n",
       "      <td>1.636139</td>\n",
       "      <td>-0.283941</td>\n",
       "      <td>0.050966</td>\n",
       "      <td>-1.044173</td>\n",
       "      <td>-2.044518</td>\n",
       "      <td>-4.157472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518181</td>\n",
       "      <td>-0.485885</td>\n",
       "      <td>0.153331</td>\n",
       "      <td>-0.867391</td>\n",
       "      <td>3.852027</td>\n",
       "      <td>3.559970</td>\n",
       "      <td>0.754794</td>\n",
       "      <td>0.072521</td>\n",
       "      <td>-2.605920</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0         NaN -0.176595 -4.126644 -2.390884 -1.366659 -0.460177  1.521421   \n",
       "1    0.267386       NaN -1.820798  1.540020  1.656770  0.447912  6.484100   \n",
       "2    2.946515 -1.594067       NaN  0.403844 -1.733342  0.274193  2.960081   \n",
       "3   -4.581082 -0.001274  1.197022       NaN -0.416290 -1.941236  0.290991   \n",
       "4   -2.123360 -0.266587  1.781999 -0.039342       NaN  0.895856  3.756880   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.318539  0.539550 -0.144831  1.402720  2.018928 -0.033435 -0.763604   \n",
       "996 -5.843779  0.341371 -0.612153 -0.209380 -1.398469  0.550250 -1.623379   \n",
       "997  3.406411  0.321762  0.286231  2.116516 -1.548059 -1.626494  3.787104   \n",
       "998 -2.167186  0.627939 -0.993588  0.902711 -1.024744 -0.416702  3.966772   \n",
       "999 -3.621659 -1.628561 -1.991653  3.852027  1.636139 -0.283941  0.050966   \n",
       "\n",
       "           7         8         9   ...        90        91        92  \\\n",
       "0    5.328470 -2.919639 -6.216557  ... -1.919015 -1.603442 -0.867395   \n",
       "1    2.356129 -1.129611  3.195601  ...  1.394421 -1.872976 -0.382098   \n",
       "2    0.326221  0.393324  0.229915  ... -0.290845 -0.076589 -4.660688   \n",
       "3    0.507716 -0.397205  4.399152  ...  1.046033 -4.498888  7.150844   \n",
       "4   -4.583167  1.652762  7.673453  ...  1.371734  4.458045  3.576609   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995 -4.475018  1.098775  2.187650  ...  1.163138  1.427695  0.753621   \n",
       "996 -0.924526 -2.274803 -3.090194  ...  1.998539 -0.695267  1.238735   \n",
       "997  2.476920 -2.113878 -7.427621  ... -2.762413 -2.860776 -6.281361   \n",
       "998  6.068817 -2.394340 -1.352014  ... -0.981470 -2.427518 -0.065137   \n",
       "999 -1.044173 -2.044518 -4.157472  ...  0.518181 -0.485885  0.153331   \n",
       "\n",
       "           93        94        95        96        97        98        99  \n",
       "0   -1.825951 -2.390884  4.107535  3.817897 -0.823303 -5.271267  2.353398  \n",
       "1   -1.980864  1.540020 -1.267888 -1.843256  1.105676 -0.344550 -6.653773  \n",
       "2   -1.652196  0.403844 -4.317565 -2.506476  3.422634 -0.272146 -3.345401  \n",
       "3    0.722794 -2.944502 -0.081950  0.186089 -7.066950  2.488842 -2.770303  \n",
       "4   -1.538929 -0.039342 -2.613114 -3.117484 -2.125028  0.143158 -8.249535  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995  0.467884  1.402720       NaN -2.008609  0.279494  4.702728 -2.272688  \n",
       "996  1.192938 -0.209380 -0.972033       NaN -2.624541  0.013214  1.422758  \n",
       "997 -3.061634  2.116516  6.246774 -0.847790       NaN -8.109827  2.108502  \n",
       "998 -1.653230  0.902711  1.644251 -0.421722 -3.231510       NaN -1.626739  \n",
       "999 -0.867391  3.852027  3.559970  0.754794  0.072521 -2.605920       NaN  \n",
       "\n",
       "[1000 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = pd.read_csv('data_A2.csv', sep = ',', header = None, na_values = '?')\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887926e7-d8fc-437e-aba2-9a5db7268d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "..  ..\n",
       "995  1\n",
       "996  0\n",
       "997  0\n",
       "998  1\n",
       "999  1\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('labels_A2.csv', sep=',', header=None, na_values ='?', dtype='int32')\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bad3dbc-d706-45c0-b974-69e6c0b3c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1000, 100)\n"
     ]
    }
   ],
   "source": [
    "y = labels.to_numpy()\n",
    "X = DATA.to_numpy()\n",
    "\n",
    "y = y.astype('int')\n",
    "\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def6059-ca11-4d04-a566-be6f73728449",
   "metadata": {},
   "source": [
    "### IMPUTING DATA TO REMOVE 'NaN' VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a9479-7f9e-4241-8251-cb8befc01ff5",
   "metadata": {},
   "source": [
    "Firstly, creating copies of the dataset and imputing these copies with different strategies to find the one that returns the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebb36f6-a5c0-4b81-8a5a-951a6393da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03640934 -0.17659526 -4.12664374 ... -0.82330291 -5.27126666\n",
      "   2.35339793]\n",
      " [ 0.26738568  0.01051725 -1.8207978  ...  1.10567555 -0.34454961\n",
      "  -6.6537733 ]\n",
      " [ 2.94651515 -1.5940672   0.53939977 ...  3.42263394 -0.27214566\n",
      "  -3.34540104]\n",
      " ...\n",
      " [ 3.40641099  0.32176174  0.28623093 ...  0.1004745  -8.10982707\n",
      "   2.10850165]\n",
      " [-2.16718563  0.62793907 -0.99358794 ... -3.23150977 -0.15775602\n",
      "  -1.62673851]\n",
      " [-3.62165864 -1.62856111 -1.99165251 ...  0.07252107 -2.60592028\n",
      "  -0.26877021]]\n",
      "[[-0.10388478 -0.17659526 -4.12664374 ... -0.82330291 -5.27126666\n",
      "   2.35339793]\n",
      " [ 0.26738568  0.04293379 -1.8207978  ...  1.10567555 -0.34454961\n",
      "  -6.6537733 ]\n",
      " [ 2.94651515 -1.5940672   0.39221346 ...  3.42263394 -0.27214566\n",
      "  -3.34540104]\n",
      " ...\n",
      " [ 3.40641099  0.32176174  0.28623093 ...  0.27599016 -8.10982707\n",
      "   2.10850165]\n",
      " [-2.16718563  0.62793907 -0.99358794 ... -3.23150977 -0.11919578\n",
      "  -1.62673851]\n",
      " [-3.62165864 -1.62856111 -1.99165251 ...  0.07252107 -2.60592028\n",
      "  -0.10275144]]\n",
      "[[-12.91301453  -0.17659526  -4.12664374 ...  -0.82330291  -5.27126666\n",
      "    2.35339793]\n",
      " [  0.26738568  -3.60456667  -1.8207978  ...   1.10567555  -0.34454961\n",
      "   -6.6537733 ]\n",
      " [  2.94651515  -1.5940672  -12.1428896  ...   3.42263394  -0.27214566\n",
      "   -3.34540104]\n",
      " ...\n",
      " [  3.40641099   0.32176174   0.28623093 ... -17.23819666  -8.10982707\n",
      "    2.10850165]\n",
      " [ -2.16718563   0.62793907  -0.99358794 ...  -3.23150977 -14.46995945\n",
      "   -1.62673851]\n",
      " [ -3.62165864  -1.62856111  -1.99165251 ...   0.07252107  -2.60592028\n",
      "  -14.08712949]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "isnan = np.isnan(X)\n",
    "\n",
    "X_mean_copy = X.copy()\n",
    "X_median_copy = X.copy()\n",
    "X_mf_copy = X.copy()\n",
    "\n",
    "imputing = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputing.fit(X_mean_copy)\n",
    "X_filled_mean = imputing.transform(X_mean_copy)\n",
    "\n",
    "imputing2 = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputing2.fit(X_median_copy)\n",
    "X_filled_median = imputing2.transform(X_median_copy)\n",
    "\n",
    "imputing3 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputing3.fit(X_mf_copy)\n",
    "X_filled_mf = imputing3.transform(X_mf_copy)\n",
    "\n",
    "print(X_filled_mean)\n",
    "print(X_filled_median)\n",
    "print(X_filled_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0efc21e1-1388-4c51-9ca3-8587b4a2cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Accuracy:  0.755\n",
      "StratifiedKFold Mean test accuracy: 69.875%\n",
      "\n",
      "0.69875\n",
      "Tree Accuracy:  0.775\n",
      "StratifiedKFold Mean test accuracy: 70.500%\n",
      "\n",
      "0.7050000000000001\n",
      "Tree Accuracy:  0.69\n",
      "StratifiedKFold Mean test accuracy: 71.250%\n",
      "\n",
      "0.7125\n",
      "Tree Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 72.250%\n",
      "\n",
      "0.7224999999999999\n",
      "Tree Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 71.125%\n",
      "\n",
      "0.71125\n",
      "Tree Accuracy:  0.775\n",
      "StratifiedKFold Mean test accuracy: 71.125%\n",
      "\n",
      "0.71125\n",
      "Tree Accuracy:  0.715\n",
      "StratifiedKFold Mean test accuracy: 71.500%\n",
      "\n",
      "0.7150000000000001\n",
      "Tree Accuracy:  0.69\n",
      "StratifiedKFold Mean test accuracy: 71.125%\n",
      "\n",
      "0.7112499999999999\n",
      "Tree Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 72.125%\n",
      "\n",
      "0.7212500000000001\n",
      "Tree Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 71.000%\n",
      "\n",
      "0.71\n",
      "[0.69875, 0.7050000000000001, 0.7125, 0.7224999999999999, 0.71125, 0.71125, 0.7150000000000001, 0.7112499999999999, 0.7212500000000001, 0.71]\n",
      "Mean CV Score:  0.711875\n",
      "Mean Tree Score:  0.724\n"
     ]
    }
   ],
   "source": [
    "seed = 333\n",
    "\n",
    "meanTreeCVMeans = []\n",
    "meanTreeScoreMeans = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filled_mean, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    meanTree = RandomForestClassifier(random_state= testseed)\n",
    "    meanTree.fit(X_train, y_train.ravel())\n",
    "    predicted = meanTree.predict(X_test)\n",
    "    print(\"Tree Accuracy: \", accuracy_score(y_test, predicted))\n",
    "    meanTreeScoreMeans.append(accuracy_score(y_test, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(meanTree, X_train, y_train.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(score)\n",
    "    testseed += 50\n",
    "    meanTreeCVMeans.append(score)\n",
    "    \n",
    "print(meanTreeCVMeans)\n",
    "\n",
    "meanTreeScore = np.mean(meanTreeCVMeans)\n",
    "meanTreeOutputScore = np.mean(meanTreeScoreMeans)\n",
    "\n",
    "print(\"Mean CV Score: \", meanTreeScore)\n",
    "print(\"Mean Tree Score: \", meanTreeOutputScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463723bf-2eb0-4899-ae4a-a9345a7ee3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Accuracy:  0.775\n",
      "StratifiedKFold Mean test accuracy: 68.500%\n",
      "\n",
      "0.6849999999999999\n",
      "Tree Accuracy:  0.76\n",
      "StratifiedKFold Mean test accuracy: 70.625%\n",
      "\n",
      "0.7062499999999999\n",
      "Tree Accuracy:  0.73\n",
      "StratifiedKFold Mean test accuracy: 71.125%\n",
      "\n",
      "0.7112499999999999\n",
      "Tree Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 72.125%\n",
      "\n",
      "0.7212500000000001\n",
      "Tree Accuracy:  0.71\n",
      "StratifiedKFold Mean test accuracy: 70.375%\n",
      "\n",
      "0.70375\n",
      "Tree Accuracy:  0.765\n",
      "StratifiedKFold Mean test accuracy: 70.125%\n",
      "\n",
      "0.7012499999999999\n",
      "Tree Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 72.000%\n",
      "\n",
      "0.72\n",
      "Tree Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 71.250%\n",
      "\n",
      "0.7125000000000001\n",
      "Tree Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 72.625%\n",
      "\n",
      "0.72625\n",
      "Tree Accuracy:  0.695\n",
      "StratifiedKFold Mean test accuracy: 71.750%\n",
      "\n",
      "0.7174999999999999\n",
      "[0.6849999999999999, 0.7062499999999999, 0.7112499999999999, 0.7212500000000001, 0.70375, 0.7012499999999999, 0.72, 0.7125000000000001, 0.72625, 0.7174999999999999]\n",
      "Mean CV Score:  0.7105\n",
      "Mean Tree Score:  0.7275000000000001\n"
     ]
    }
   ],
   "source": [
    "medianTreeCVMeans = []\n",
    "medianTreeScoreMeans = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(X_filled_median, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    medianTree = RandomForestClassifier(random_state= testseed)\n",
    "    medianTree.fit(X_train2, y_train2.ravel())\n",
    "    predicted2 = medianTree.predict(X_test2)\n",
    "    print(\"Tree Accuracy: \", accuracy_score(y_test2, predicted2))\n",
    "    medianTreeScoreMeans.append(accuracy_score(y_test2, predicted2))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(medianTree, X_train2, y_train2.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(score)\n",
    "    testseed += 50\n",
    "    medianTreeCVMeans.append(score)\n",
    "    \n",
    "print(medianTreeCVMeans)\n",
    "\n",
    "medianTreeScore = np.mean(medianTreeCVMeans)\n",
    "medianTreeOutputScore = np.mean(medianTreeScoreMeans)\n",
    "\n",
    "print(\"Mean CV Score: \", medianTreeScore)\n",
    "print(\"Mean Tree Score: \", medianTreeOutputScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63cf6a1e-bf41-4225-a783-70f007db53ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Accuracy:  0.76\n",
      "StratifiedKFold Mean test accuracy: 67.250%\n",
      "\n",
      "0.6725000000000001\n",
      "Tree Accuracy:  0.745\n",
      "StratifiedKFold Mean test accuracy: 70.750%\n",
      "\n",
      "0.7075\n",
      "Tree Accuracy:  0.73\n",
      "StratifiedKFold Mean test accuracy: 71.250%\n",
      "\n",
      "0.7125\n",
      "Tree Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 73.000%\n",
      "\n",
      "0.73\n",
      "Tree Accuracy:  0.75\n",
      "StratifiedKFold Mean test accuracy: 70.125%\n",
      "\n",
      "0.7012500000000002\n",
      "Tree Accuracy:  0.75\n",
      "StratifiedKFold Mean test accuracy: 70.250%\n",
      "\n",
      "0.7024999999999999\n",
      "Tree Accuracy:  0.73\n",
      "StratifiedKFold Mean test accuracy: 72.500%\n",
      "\n",
      "0.725\n",
      "Tree Accuracy:  0.695\n",
      "StratifiedKFold Mean test accuracy: 73.625%\n",
      "\n",
      "0.73625\n",
      "Tree Accuracy:  0.695\n",
      "StratifiedKFold Mean test accuracy: 72.625%\n",
      "\n",
      "0.72625\n",
      "Tree Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 71.625%\n",
      "\n",
      "0.7162500000000002\n",
      "[0.6725000000000001, 0.7075, 0.7125, 0.73, 0.7012500000000002, 0.7024999999999999, 0.725, 0.73625, 0.72625, 0.7162500000000002]\n",
      "Mean CV Score:  0.7130000000000001\n",
      "Mean Tree Score:  0.7295\n"
     ]
    }
   ],
   "source": [
    "mfTreeCVMeans = []\n",
    "mfTreeScoreMeans = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train3, X_test3, y_train3, y_test3 = train_test_split(X_filled_mf, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    mfTree = RandomForestClassifier(random_state= testseed)\n",
    "    mfTree.fit(X_train3, y_train3.ravel())\n",
    "    predicted3 = mfTree.predict(X_test3)\n",
    "    print(\"Tree Accuracy: \", accuracy_score(y_test3, predicted3))\n",
    "    mfTreeScoreMeans.append(accuracy_score(y_test3, predicted3))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(mfTree, X_train3, y_train3.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(score)\n",
    "    testseed += 50\n",
    "    mfTreeCVMeans.append(score)\n",
    "    \n",
    "print(mfTreeCVMeans)\n",
    "\n",
    "mfTreeCVScore = np.mean(mfTreeCVMeans)\n",
    "mfTreeOutputScore = np.mean(mfTreeScoreMeans)\n",
    "\n",
    "print(\"Mean CV Score: \", mfTreeCVScore)\n",
    "print(\"Mean Tree Score: \", mfTreeOutputScore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b160b2-84c5-4d51-860a-eab69db7dcaf",
   "metadata": {},
   "source": [
    "Applying imputation with median values to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b75e4bb1-4d9d-4f4e-81db-ff65b1dc5e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10388478 -0.17659526 -4.12664374 ... -0.82330291 -5.27126666\n",
      "   2.35339793]\n",
      " [ 0.26738568  0.04293379 -1.8207978  ...  1.10567555 -0.34454961\n",
      "  -6.6537733 ]\n",
      " [ 2.94651515 -1.5940672   0.39221346 ...  3.42263394 -0.27214566\n",
      "  -3.34540104]\n",
      " ...\n",
      " [ 3.40641099  0.32176174  0.28623093 ...  0.27599016 -8.10982707\n",
      "   2.10850165]\n",
      " [-2.16718563  0.62793907 -0.99358794 ... -3.23150977 -0.11919578\n",
      "  -1.62673851]\n",
      " [-3.62165864 -1.62856111 -1.99165251 ...  0.07252107 -2.60592028\n",
      "  -0.10275144]]\n"
     ]
    }
   ],
   "source": [
    "imputing = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputing.fit(X)\n",
    "newX = imputing.transform(X)\n",
    "\n",
    "print(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5eb4f-3759-4648-a37f-b2cc74a9de85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d29a904d-9cef-4992-be22-6e78cb104d63",
   "metadata": {},
   "source": [
    "TASK 2\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5622a866-10fb-4e3b-b380-1da8571db20e",
   "metadata": {},
   "source": [
    "Utilizing RFE feature selection to further process the data to get the 10 best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2405a1c-f3ea-4bce-bf64-97fc830f958b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "[[-0.10388478 -2.91963929 -0.20433017 ... -0.20760601 -0.72289957\n",
      "  -1.82595091]\n",
      " [ 0.26738568 -1.12961117  0.06619492 ... -0.76806967  2.49297253\n",
      "  -1.98086402]\n",
      " [ 2.94651515  0.39332371 -0.67137599 ...  0.81093247 -0.24785755\n",
      "  -1.65219553]\n",
      " ...\n",
      " [ 3.40641099 -2.11387845  0.47462734 ...  0.58499158  1.43568029\n",
      "  -3.06163402]\n",
      " [-2.16718563 -2.39433995  0.23433594 ...  0.9678646  -1.98683152\n",
      "  -1.65323029]\n",
      " [-3.62165864 -2.0445179  -0.30160947 ... -2.89039235  2.61232767\n",
      "  -0.86739051]]\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "featureSelect = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=10)\n",
    "featureSelect.fit(newX, y)\n",
    "newX= featureSelect.fit_transform(newX, y)\n",
    "\n",
    "print(featureSelect.support_)\n",
    "\n",
    "print(newX)\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ae4ce-c37c-4a86-aaa9-2d595891c9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c214cd4f-6981-4f5d-8546-786501dfd88d",
   "metadata": {},
   "source": [
    "TASK 3\n",
    "====== "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857b885-7a47-48b4-b954-2f6e910c7da4",
   "metadata": {},
   "source": [
    "DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4741de18-4de6-44b7-83cd-2ecc1a7e693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.665\n",
      "StratifiedKFold Mean test accuracy: 63.000%\n",
      "\n",
      "CV score:  0.6300000000000001 \n",
      "\n",
      "Decision Tree Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 61.700%\n",
      "\n",
      "CV score:  0.617 \n",
      "\n",
      "Decision Tree Accuracy:  0.61\n",
      "StratifiedKFold Mean test accuracy: 62.000%\n",
      "\n",
      "CV score:  0.62 \n",
      "\n",
      "Decision Tree Accuracy:  0.565\n",
      "StratifiedKFold Mean test accuracy: 62.600%\n",
      "\n",
      "CV score:  0.626 \n",
      "\n",
      "Decision Tree Accuracy:  0.61\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Tree Accuracy:  0.685\n",
      "StratifiedKFold Mean test accuracy: 63.300%\n",
      "\n",
      "CV score:  0.633 \n",
      "\n",
      "Decision Tree Accuracy:  0.64\n",
      "StratifiedKFold Mean test accuracy: 62.200%\n",
      "\n",
      "CV score:  0.622 \n",
      "\n",
      "Decision Tree Accuracy:  0.6\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Tree Accuracy:  0.61\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Tree Accuracy:  0.56\n",
      "StratifiedKFold Mean test accuracy: 62.800%\n",
      "\n",
      "CV score:  0.628 \n",
      "\n",
      "[0.665, 0.615, 0.61, 0.565, 0.61, 0.685, 0.64, 0.6, 0.61, 0.56]\n",
      "Decision Tree mean score for the dataset is:  0.616\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "DecisionTreeCVMeans = []\n",
    "DecisionTreeMeans = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    decisionTree = DecisionTreeClassifier(random_state= testseed)\n",
    "    decisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionTree.predict(X_test4)\n",
    "    print(\"Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionTreeMeans.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(DecisionTreeMeans)\n",
    "\n",
    "DecisionTreeScore = np.mean(DecisionTreeMeans)\n",
    "\n",
    "DecisionTreeSDframe = pd.DataFrame(DecisionTreeMeans)\n",
    "DecisionTreeSD = DecisionTreeSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Tree mean score for the dataset is: \", DecisionTreeScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640565b8-1076-489b-abbb-75755925f8b4",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffe92782-7e9a-4b35-8bf9-b5757cfdbfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.74\n",
      "RepeatedKFold Mean test accuracy: 71.500%\n",
      "\n",
      "CV score:  0.7149999999999999 \n",
      "\n",
      "Random Forest Accuracy:  0.72\n",
      "RepeatedKFold Mean test accuracy: 71.650%\n",
      "\n",
      "CV score:  0.7164999999999999 \n",
      "\n",
      "Random Forest Accuracy:  0.695\n",
      "RepeatedKFold Mean test accuracy: 71.660%\n",
      "\n",
      "CV score:  0.7166 \n",
      "\n",
      "Random Forest Accuracy:  0.71\n",
      "RepeatedKFold Mean test accuracy: 71.240%\n",
      "\n",
      "CV score:  0.7124000000000001 \n",
      "\n",
      "Random Forest Accuracy:  0.745\n",
      "RepeatedKFold Mean test accuracy: 71.530%\n",
      "\n",
      "CV score:  0.7153 \n",
      "\n",
      "Random Forest Accuracy:  0.745\n",
      "RepeatedKFold Mean test accuracy: 72.020%\n",
      "\n",
      "CV score:  0.7202 \n",
      "\n",
      "Random Forest Accuracy:  0.725\n",
      "RepeatedKFold Mean test accuracy: 71.280%\n",
      "\n",
      "CV score:  0.7127999999999999 \n",
      "\n",
      "Random Forest Accuracy:  0.685\n",
      "RepeatedKFold Mean test accuracy: 71.940%\n",
      "\n",
      "CV score:  0.7193999999999999 \n",
      "\n",
      "Random Forest Accuracy:  0.69\n",
      "RepeatedKFold Mean test accuracy: 71.390%\n",
      "\n",
      "CV score:  0.7139 \n",
      "\n",
      "Random Forest Accuracy:  0.705\n",
      "RepeatedKFold Mean test accuracy: 71.770%\n",
      "\n",
      "CV score:  0.7177000000000001 \n",
      "\n",
      "[0.74, 0.72, 0.695, 0.71, 0.745, 0.745, 0.725, 0.685, 0.69, 0.705]\n",
      "Random Forest mean score for the dataset is:  0.716\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(random_state = seed)\n",
    "\n",
    "RandomForestCVMeans = []\n",
    "RandomForestMeans = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    randomForest = RandomForestClassifier(random_state= testseed)\n",
    "    randomForest.fit(X_train4, y_train4.ravel())\n",
    "    predicted = randomForest.predict(X_test4)\n",
    "    print(\"Random Forest Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    RandomForestMeans.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = RepeatedKFold(n_splits = 5, random_state = testseed)\n",
    "    scoreList = cross_val_score(randomForest, newX, y.ravel(), cv=multi)\n",
    "    print(f\"RepeatedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    RandomForestCVMeans.append(score)\n",
    "    \n",
    "print(RandomForestMeans)\n",
    "\n",
    "RandomForestScore = np.mean(RandomForestMeans)\n",
    "\n",
    "RandomForestSDframe = pd.DataFrame(RandomForestMeans)\n",
    "RandomForestSD = RandomForestSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Random Forest mean score for the dataset is: \", RandomForestScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab72eb8-ed13-485a-b4fb-9a497086e50e",
   "metadata": {},
   "source": [
    "DECISION STUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d9d7d2c-577f-4502-8fa6-6345f1e1bd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Stump Accuracy:  0.65\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Stump Accuracy:  0.595\n",
      "StratifiedKFold Mean test accuracy: 61.300%\n",
      "\n",
      "CV score:  0.613 \n",
      "\n",
      "Decision Stump Accuracy:  0.58\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Stump Accuracy:  0.625\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.592 \n",
      "\n",
      "Decision Stump Accuracy:  0.625\n",
      "StratifiedKFold Mean test accuracy: 60.800%\n",
      "\n",
      "CV score:  0.6079999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.595\n",
      "StratifiedKFold Mean test accuracy: 60.300%\n",
      "\n",
      "CV score:  0.603 \n",
      "\n",
      "Decision Stump Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Stump Accuracy:  0.555\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.589 \n",
      "\n",
      "Decision Stump Accuracy:  0.535\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.5919999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.555\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.5890000000000001 \n",
      "\n",
      "[0.65, 0.595, 0.58, 0.625, 0.625, 0.595, 0.62, 0.555, 0.535, 0.555]\n",
      "Decision Stump mean score for the dataset is:  0.5935\n"
     ]
    }
   ],
   "source": [
    "decisionStump = DecisionTreeClassifier(max_depth=1,random_state = seed)\n",
    "\n",
    "DecisionStumpCVMeans = []\n",
    "DecisionStumpMeans = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    decisionStump = DecisionTreeClassifier(max_depth=1,random_state = testseed)\n",
    "    decisionStump.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionStump.predict(X_test4)\n",
    "    print(\"Decision Stump Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionStumpMeans.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionStump, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionStumpCVMeans.append(score)\n",
    "    \n",
    "print(DecisionStumpMeans)\n",
    "\n",
    "DecisionStumpScore = np.mean(DecisionStumpMeans)\n",
    "\n",
    "DecisionStumpframe = pd.DataFrame(DecisionStumpMeans)\n",
    "DecisionStumpSD = DecisionStumpframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Stump mean score for the dataset is: \", DecisionStumpScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2050b7d-f8cd-4a99-b3c7-27edf953977c",
   "metadata": {},
   "source": [
    "PRUNED DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9e47335-a56b-49f4-8691-90914c6bd183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005029861888764468\n",
      "Pruned Decision Tree Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 68.200%\n",
      "\n",
      "CV score:  0.682 \n",
      "\n",
      "0.0030133928571428573\n",
      "Pruned Decision Tree Accuracy:  0.63\n",
      "StratifiedKFold Mean test accuracy: 65.000%\n",
      "\n",
      "CV score:  0.6500000000000001 \n",
      "\n",
      "0.00761278195488722\n",
      "Pruned Decision Tree Accuracy:  0.635\n",
      "StratifiedKFold Mean test accuracy: 67.600%\n",
      "\n",
      "CV score:  0.676 \n",
      "\n",
      "0.005547823339320087\n",
      "Pruned Decision Tree Accuracy:  0.65\n",
      "StratifiedKFold Mean test accuracy: 64.900%\n",
      "\n",
      "CV score:  0.649 \n",
      "\n",
      "0.004726562499999998\n",
      "Pruned Decision Tree Accuracy:  0.735\n",
      "StratifiedKFold Mean test accuracy: 69.600%\n",
      "\n",
      "CV score:  0.696 \n",
      "\n",
      "0.006694773906597486\n",
      "Pruned Decision Tree Accuracy:  0.68\n",
      "StratifiedKFold Mean test accuracy: 68.300%\n",
      "\n",
      "CV score:  0.683 \n",
      "\n",
      "0.010689754587315331\n",
      "Pruned Decision Tree Accuracy:  0.67\n",
      "StratifiedKFold Mean test accuracy: 65.600%\n",
      "\n",
      "CV score:  0.6559999999999999 \n",
      "\n",
      "0.008037587772487724\n",
      "Pruned Decision Tree Accuracy:  0.545\n",
      "StratifiedKFold Mean test accuracy: 67.000%\n",
      "\n",
      "CV score:  0.67 \n",
      "\n",
      "0.013040236928104576\n",
      "Pruned Decision Tree Accuracy:  0.65\n",
      "StratifiedKFold Mean test accuracy: 64.400%\n",
      "\n",
      "CV score:  0.6440000000000001 \n",
      "\n",
      "0.0029755378028404338\n",
      "Pruned Decision Tree Accuracy:  0.56\n",
      "StratifiedKFold Mean test accuracy: 66.600%\n",
      "\n",
      "CV score:  0.666 \n",
      "\n",
      "[0.7, 0.63, 0.635, 0.65, 0.735, 0.68, 0.67, 0.545, 0.65, 0.56]\n",
      "Pruned Decision Tree mean score for the dataset is:  0.6455\n"
     ]
    }
   ],
   "source": [
    "prunedDecisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "prunedDecisionTreeCVMeans = []\n",
    "prunedDecisionTreeMeans = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    X_train4VAL, X_val, y_train4VAL, y_val = train_test_split(X_train4, y_train4, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    treePath = DecisionTreeClassifier(random_state=testseed).cost_complexity_pruning_path(X_train4VAL, y_train4VAL)\n",
    "    \n",
    "    accuracyScores = []\n",
    "    \n",
    "    for i in treePath.ccp_alphas:\n",
    "        accuracyScores.append(DecisionTreeClassifier(ccp_alpha=i, random_state=testseed).fit(X_train4VAL, y_train4VAL).score(X_val, y_val))\n",
    "        \n",
    "    bestAlphaValue = treePath.ccp_alphas[np.argmax(accuracyScores)]\n",
    "    print(bestAlphaValue)\n",
    "    \n",
    "    prunedDecisionTree = DecisionTreeClassifier(ccp_alpha=bestAlphaValue, random_state = testseed)\n",
    "    prunedDecisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = prunedDecisionTree.predict(X_test4)\n",
    "    print(\"Pruned Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    prunedDecisionTreeMeans.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(prunedDecisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    prunedDecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(prunedDecisionTreeMeans)\n",
    "\n",
    "prunedDecisionTreeScore = np.mean(prunedDecisionTreeMeans)\n",
    "\n",
    "prunedDecisionTreeframe = pd.DataFrame(prunedDecisionTreeMeans)\n",
    "prunedDecisionTreeSD = prunedDecisionTreeframe.std()\n",
    "\n",
    "\n",
    "print(\"Pruned Decision Tree mean score for the dataset is: \", prunedDecisionTreeScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04ea252f-828f-4c79-b1f8-c24fe2ef4e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Decision Tree  Random Forest  Decision Stump  Pruned Decision Tree\n",
      "0          0.680          0.740           0.640                 0.690\n",
      "1          0.565          0.705           0.585                 0.620\n",
      "2          0.590          0.730           0.565                 0.625\n",
      "3          0.555          0.710           0.610                 0.645\n",
      "4          0.600          0.765           0.640                 0.690\n",
      "5          0.665          0.760           0.605                 0.680\n",
      "6          0.645          0.725           0.610                 0.670\n",
      "7          0.655          0.690           0.550                 0.645\n",
      "8          0.595          0.685           0.510                 0.665\n",
      "9          0.545          0.700           0.530                 0.570\n",
      "RankResult(rankdf=\n",
      "                      meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "Random Forest              1.0  0.7210  0.027869  0.696654  0.745346   \n",
      "Pruned Decision Tree       2.1  0.6500  0.037565  0.625654  0.674346   \n",
      "Decision Tree              3.2  0.6095  0.048503  0.585154  0.633846   \n",
      "Decision Stump             3.7  0.5845  0.044687  0.560154  0.608846   \n",
      "\n",
      "                     effect_size   magnitude  \n",
      "Random Forest                0.0  negligible  \n",
      "Pruned Decision Tree    2.146702       large  \n",
      "Decision Tree           2.818873       large  \n",
      "Decision Stump          3.665429       large  \n",
      "pvalue=7.513648457899441e-11\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.3932282030582428, 0.5819944143295288, 0.5498653054237366, 0.28460416197776794]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.4226124494894943\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=10\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "The statistical analysis was conducted for 4 populations with 10 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=0.285). Therefore, we assume that all populations are normal.\n",
      "We applied Bartlett's test for homogeneity and failed to reject the null hypothesis (p=0.423) that the data is homoscedastic. Thus, we assume that our data is homoscedastic.\n",
      "Because we have more than two populations and all populations are normal and homoscedastic, we use repeated measures ANOVA as omnibus test to determine if there are any significant differences between the mean values of the populations. If the results of the ANOVA test are significant, we use the post-hoc Tukey HSD test to infer which differences are significant. We report the mean value (M) and the standard deviation (SD) for each population. Populations are significantly different if their confidence intervals are not overlapping.\n",
      "We reject the null hypothesis (p=0.000) of the repeated measures ANOVA that there is a difference between the mean values of the populations Random Forest (M=0.721+-0.024, SD=0.028), Pruned Decision Tree (M=0.650+-0.024, SD=0.038), Decision Tree (M=0.609+-0.024, SD=0.049), and Decision Stump (M=0.585+-0.024, SD=0.045). Therefore, we assume that there is a statistically significant difference between the mean values of the populations.\n",
      "Based on post-hoc Tukey HSD test, we assume that all differences between the populations are significant.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\sandbox\\stats\\multicomp.py:775: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax1.set_yticklabels(np.insert(self.groupsunique.astype(str), 0, ''))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'95.0% Confidence Intervals of the Mean'}>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_means = {\n",
    "    'Decision Tree':DecisionTreeMeans,\n",
    "    'Random Forest':RandomForestMeans,\n",
    "    'Decision Stump':DecisionStumpMeans,\n",
    "    'Pruned Decision Tree':prunedDecisionTreeMeans\n",
    "}\n",
    "\n",
    "data = pd.DataFrame (model_means, columns = ['Decision Tree', 'Random Forest', 'Decision Stump', 'Pruned Decision Tree'])\n",
    "print(data)\n",
    "results = autorank(data, verbose=False)\n",
    "print(results)\n",
    "create_report(results)\n",
    "plot_stats(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd4889-03d0-4616-a7c5-ad3f5a211813",
   "metadata": {},
   "source": [
    "TASK 4\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c30cd-d30c-458c-8e97-d641a209ad52",
   "metadata": {},
   "source": [
    "Adding additive noise to the dataset and re-training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d1c71a2e-56a2-409a-9321-e2b6887b6245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10223385 -2.88661551 -0.20217874 ... -0.21596364 -0.72171868\n",
      "  -1.84822607]\n",
      " [ 0.26940068 -1.10072357  0.06484207 ... -0.76880475  2.49261328\n",
      "  -1.96020332]\n",
      " [ 2.94892061  0.35150328 -0.67596483 ...  0.81659159 -0.25001544\n",
      "  -1.67830134]\n",
      " ...\n",
      " [ 3.40395391 -2.10899928  0.47554047 ...  0.5736226   1.44608109\n",
      "  -3.08337013]\n",
      " [-2.17226587 -2.33107503  0.23340754 ...  0.95827699 -1.99405489\n",
      "  -1.65666617]\n",
      " [-3.61933918 -2.04246296 -0.2995694  ... -2.8761662   2.61677841\n",
      "  -0.89293053]]\n"
     ]
    }
   ],
   "source": [
    "random = np.random.default_rng()\n",
    "\n",
    "AddiNoise = np.random.normal(0, 0.2, np.shape(newX))\n",
    "\n",
    "xAdditiveNoise = newX + np.multiply(AddiNoise, np.average(newX, axis=0))\n",
    "\n",
    "print(xAdditiveNoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deba3a7-0277-4f48-8f2b-f5fd0a2ff6c8",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "DECISION TREE + ADDITIVE NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4fab4de-1cc1-4910-a3c9-96096c594e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.59\n",
      "StratifiedKFold Mean test accuracy: 63.000%\n",
      "\n",
      "CV score:  0.6300000000000001 \n",
      "\n",
      "Decision Tree Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 61.700%\n",
      "\n",
      "CV score:  0.617 \n",
      "\n",
      "Decision Tree Accuracy:  0.665\n",
      "StratifiedKFold Mean test accuracy: 62.000%\n",
      "\n",
      "CV score:  0.62 \n",
      "\n",
      "Decision Tree Accuracy:  0.57\n",
      "StratifiedKFold Mean test accuracy: 62.600%\n",
      "\n",
      "CV score:  0.626 \n",
      "\n",
      "Decision Tree Accuracy:  0.61\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Tree Accuracy:  0.67\n",
      "StratifiedKFold Mean test accuracy: 63.300%\n",
      "\n",
      "CV score:  0.633 \n",
      "\n",
      "Decision Tree Accuracy:  0.58\n",
      "StratifiedKFold Mean test accuracy: 62.200%\n",
      "\n",
      "CV score:  0.622 \n",
      "\n",
      "Decision Tree Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Tree Accuracy:  0.63\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Tree Accuracy:  0.535\n",
      "StratifiedKFold Mean test accuracy: 62.800%\n",
      "\n",
      "CV score:  0.628 \n",
      "\n",
      "[0.59, 0.575, 0.665, 0.57, 0.61, 0.67, 0.58, 0.575, 0.63, 0.535]\n",
      "Decision Tree mean score for the dataset is:  0.5999999999999999\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "DecisionTreeCVMeans = []\n",
    "DecisionTreeMeans2 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(xAdditiveNoise, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    decisionTree = DecisionTreeClassifier(random_state= testseed)\n",
    "    decisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionTree.predict(X_test4)\n",
    "    print(\"Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionTreeMeans2.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(DecisionTreeMeans2)\n",
    "\n",
    "DecisionTreeScore = np.mean(DecisionTreeMeans2)\n",
    "\n",
    "DecisionTreeSDframe = pd.DataFrame(DecisionTreeMeans2)\n",
    "DecisionTreeSD = DecisionTreeSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Tree mean score for the dataset is: \", DecisionTreeScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c55e9a-82c8-481d-9102-7860d624cbb9",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "RANDOM FOREST + ADDITIVE NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03c7fefb-433c-4e42-b231-8ec3d3b307ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.735\n",
      "StratifiedKFold Mean test accuracy: 72.000%\n",
      "\n",
      "CV score:  0.72 \n",
      "\n",
      "Random Forest Accuracy:  0.735\n",
      "StratifiedKFold Mean test accuracy: 70.500%\n",
      "\n",
      "CV score:  0.705 \n",
      "\n",
      "Random Forest Accuracy:  0.695\n",
      "StratifiedKFold Mean test accuracy: 71.800%\n",
      "\n",
      "CV score:  0.7180000000000001 \n",
      "\n",
      "Random Forest Accuracy:  0.685\n",
      "StratifiedKFold Mean test accuracy: 70.800%\n",
      "\n",
      "CV score:  0.708 \n",
      "\n",
      "Random Forest Accuracy:  0.74\n",
      "StratifiedKFold Mean test accuracy: 72.700%\n",
      "\n",
      "CV score:  0.727 \n",
      "\n",
      "Random Forest Accuracy:  0.76\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.705\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.685\n",
      "StratifiedKFold Mean test accuracy: 72.300%\n",
      "\n",
      "CV score:  0.723 \n",
      "\n",
      "Random Forest Accuracy:  0.69\n",
      "StratifiedKFold Mean test accuracy: 72.200%\n",
      "\n",
      "CV score:  0.722 \n",
      "\n",
      "Random Forest Accuracy:  0.735\n",
      "StratifiedKFold Mean test accuracy: 72.100%\n",
      "\n",
      "CV score:  0.7209999999999999 \n",
      "\n",
      "[0.735, 0.735, 0.695, 0.685, 0.74, 0.76, 0.705, 0.685, 0.69, 0.735]\n",
      "Random Forest mean score for the dataset is:  0.7165\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(random_state = seed)\n",
    "\n",
    "RandomForestCVMeans = []\n",
    "RandomForestMeans2 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(xAdditiveNoise, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    randomForest = RandomForestClassifier(random_state= testseed)\n",
    "    randomForest.fit(X_train4, y_train4.ravel())\n",
    "    predicted = randomForest.predict(X_test4)\n",
    "    print(\"Random Forest Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    RandomForestMeans2.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(randomForest, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    RandomForestCVMeans.append(score)\n",
    "    \n",
    "print(RandomForestMeans2)\n",
    "\n",
    "RandomForestScore = np.mean(RandomForestMeans2)\n",
    "\n",
    "RandomForestSDframe = pd.DataFrame(RandomForestMeans2)\n",
    "RandomForestSD = RandomForestSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Random Forest mean score for the dataset is: \", RandomForestScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e8969f-7160-44ba-8a79-0fcb5f9da116",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "DECISION STUMP + ADDITIVE NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "137ed678-c4ae-49d9-8098-02c0a8174dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Stump Accuracy:  0.63\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Stump Accuracy:  0.595\n",
      "StratifiedKFold Mean test accuracy: 61.300%\n",
      "\n",
      "CV score:  0.613 \n",
      "\n",
      "Decision Stump Accuracy:  0.56\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Stump Accuracy:  0.625\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.592 \n",
      "\n",
      "Decision Stump Accuracy:  0.63\n",
      "StratifiedKFold Mean test accuracy: 60.800%\n",
      "\n",
      "CV score:  0.6079999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.59\n",
      "StratifiedKFold Mean test accuracy: 60.300%\n",
      "\n",
      "CV score:  0.603 \n",
      "\n",
      "Decision Stump Accuracy:  0.61\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Stump Accuracy:  0.555\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.589 \n",
      "\n",
      "Decision Stump Accuracy:  0.525\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.5919999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.565\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.5890000000000001 \n",
      "\n",
      "[0.63, 0.595, 0.56, 0.625, 0.63, 0.59, 0.61, 0.555, 0.525, 0.565]\n",
      "Decision Stump mean score for the dataset is:  0.5885\n"
     ]
    }
   ],
   "source": [
    "decisionStump = DecisionTreeClassifier(max_depth=1,random_state = seed)\n",
    "\n",
    "DecisionStumpCVMeans = []\n",
    "DecisionStumpMeans2 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(xAdditiveNoise, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    decisionStump = DecisionTreeClassifier(max_depth=1,random_state = testseed)\n",
    "    decisionStump.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionStump.predict(X_test4)\n",
    "    print(\"Decision Stump Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionStumpMeans2.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionStump, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionStumpCVMeans.append(score)\n",
    "    \n",
    "print(DecisionStumpMeans2)\n",
    "\n",
    "DecisionStumpScore = np.mean(DecisionStumpMeans2)\n",
    "\n",
    "DecisionStumpframe = pd.DataFrame(DecisionStumpMeans2)\n",
    "DecisionStumpSD = DecisionStumpframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Stump mean score for the dataset is: \", DecisionStumpScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409d36f-b4fd-46c2-a1c5-53422db891a5",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "PRUNED DECISION TREE + ADDITIVE NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96b6704d-efd1-48e8-9bb0-4893722f1702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004650297619047616\n",
      "Pruned Decision Tree Accuracy:  0.67\n",
      "StratifiedKFold Mean test accuracy: 67.500%\n",
      "\n",
      "CV score:  0.675 \n",
      "\n",
      "0.0070898437500000015\n",
      "Pruned Decision Tree Accuracy:  0.675\n",
      "StratifiedKFold Mean test accuracy: 68.000%\n",
      "\n",
      "CV score:  0.68 \n",
      "\n",
      "0.006985822346179853\n",
      "Pruned Decision Tree Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 68.500%\n",
      "\n",
      "CV score:  0.6849999999999999 \n",
      "\n",
      "0.023625502356813086\n",
      "Pruned Decision Tree Accuracy:  0.655\n",
      "StratifiedKFold Mean test accuracy: 61.300%\n",
      "\n",
      "CV score:  0.613 \n",
      "\n",
      "0.00770761485746424\n",
      "Pruned Decision Tree Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 67.800%\n",
      "\n",
      "CV score:  0.678 \n",
      "\n",
      "0.006650391436109654\n",
      "Pruned Decision Tree Accuracy:  0.685\n",
      "StratifiedKFold Mean test accuracy: 68.300%\n",
      "\n",
      "CV score:  0.683 \n",
      "\n",
      "0.01074090118285792\n",
      "Pruned Decision Tree Accuracy:  0.65\n",
      "StratifiedKFold Mean test accuracy: 65.600%\n",
      "\n",
      "CV score:  0.6559999999999999 \n",
      "\n",
      "0.0058370495842661185\n",
      "Pruned Decision Tree Accuracy:  0.6\n",
      "StratifiedKFold Mean test accuracy: 67.100%\n",
      "\n",
      "CV score:  0.6709999999999999 \n",
      "\n",
      "0.009745091382334647\n",
      "Pruned Decision Tree Accuracy:  0.63\n",
      "StratifiedKFold Mean test accuracy: 65.200%\n",
      "\n",
      "CV score:  0.652 \n",
      "\n",
      "0.0\n",
      "Pruned Decision Tree Accuracy:  0.535\n",
      "StratifiedKFold Mean test accuracy: 62.800%\n",
      "\n",
      "CV score:  0.628 \n",
      "\n",
      "[0.67, 0.675, 0.62, 0.655, 0.72, 0.685, 0.65, 0.6, 0.63, 0.535]\n",
      "Pruned Decision Tree mean score for the dataset is:  0.644\n"
     ]
    }
   ],
   "source": [
    "prunedDecisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "prunedDecisionTreeCVMeans = []\n",
    "prunedDecisionTreeMeans2 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(xAdditiveNoise, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    X_train4VAL, X_val, y_train4VAL, y_val = train_test_split(X_train4, y_train4, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    treePath = DecisionTreeClassifier(random_state=testseed).cost_complexity_pruning_path(X_train4VAL, y_train4VAL)\n",
    "    \n",
    "    accuracyScores = []\n",
    "    \n",
    "    for i in treePath.ccp_alphas:\n",
    "        accuracyScores.append(DecisionTreeClassifier(ccp_alpha=i, random_state=testseed).fit(X_train4VAL, y_train4VAL).score(X_val, y_val))\n",
    "        \n",
    "    bestAlphaValue = treePath.ccp_alphas[np.argmax(accuracyScores)]\n",
    "    print(bestAlphaValue)\n",
    "\n",
    "    prunedDecisionTree = DecisionTreeClassifier(ccp_alpha=bestAlphaValue, random_state = testseed)\n",
    "    prunedDecisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = prunedDecisionTree.predict(X_test4)\n",
    "    print(\"Pruned Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    prunedDecisionTreeMeans2.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(prunedDecisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    prunedDecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(prunedDecisionTreeMeans2)\n",
    "\n",
    "prunedDecisionTreeScore = np.mean(prunedDecisionTreeMeans2)\n",
    "\n",
    "prunedDecisionTreeframe = pd.DataFrame(prunedDecisionTreeMeans2)\n",
    "prunedDecisionTreeSD = prunedDecisionTreeframe.std()\n",
    "\n",
    "\n",
    "print(\"Pruned Decision Tree mean score for the dataset is: \", prunedDecisionTreeScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2aa7637-ed41-4cca-b191-8fa0dc0359cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Decision Tree  Random Forest  Decision Stump  Pruned Decision Tree\n",
      "0          0.590          0.735           0.630                 0.670\n",
      "1          0.575          0.735           0.595                 0.675\n",
      "2          0.665          0.695           0.560                 0.620\n",
      "3          0.570          0.685           0.625                 0.655\n",
      "4          0.610          0.740           0.630                 0.720\n",
      "5          0.670          0.760           0.590                 0.685\n",
      "6          0.580          0.705           0.610                 0.650\n",
      "7          0.575          0.685           0.555                 0.600\n",
      "8          0.630          0.690           0.525                 0.630\n",
      "9          0.535          0.735           0.565                 0.535\n",
      "RankResult(rankdf=\n",
      "                      meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "Random Forest              1.0  0.7165  0.027391  0.692038  0.740962   \n",
      "Pruned Decision Tree       2.3  0.6440  0.051467  0.619538  0.668462   \n",
      "Decision Stump             3.3  0.5885  0.036213  0.564038  0.612962   \n",
      "Decision Tree              3.4  0.6000  0.043461  0.575538  0.624462   \n",
      "\n",
      "                     effect_size   magnitude  \n",
      "Random Forest                0.0  negligible  \n",
      "Pruned Decision Tree    1.758599       large  \n",
      "Decision Stump           3.98672       large  \n",
      "Decision Tree           3.207063       large  \n",
      "pvalue=1.6750179976856445e-08\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.3733724057674408, 0.11535626649856567, 0.41450682282447815, 0.7445244193077087]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.3185738990251283\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=10\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "The statistical analysis was conducted for 4 populations with 10 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=0.115). Therefore, we assume that all populations are normal.\n",
      "We applied Bartlett's test for homogeneity and failed to reject the null hypothesis (p=0.319) that the data is homoscedastic. Thus, we assume that our data is homoscedastic.\n",
      "Because we have more than two populations and all populations are normal and homoscedastic, we use repeated measures ANOVA as omnibus test to determine if there are any significant differences between the mean values of the populations. If the results of the ANOVA test are significant, we use the post-hoc Tukey HSD test to infer which differences are significant. We report the mean value (M) and the standard deviation (SD) for each population. Populations are significantly different if their confidence intervals are not overlapping.\n",
      "We reject the null hypothesis (p=0.000) of the repeated measures ANOVA that there is a difference between the mean values of the populations Random Forest (M=0.717+-0.024, SD=0.027), Pruned Decision Tree (M=0.644+-0.024, SD=0.051), Decision Stump (M=0.589+-0.024, SD=0.036), and Decision Tree (M=0.600+-0.024, SD=0.043). Therefore, we assume that there is a statistically significant difference between the mean values of the populations.\n",
      "Based post-hoc Tukey HSD test, we assume that there are no significant differences within the following groups: Decision Stump and Decision Tree. All other differences are significant.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\sandbox\\stats\\multicomp.py:775: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax1.set_yticklabels(np.insert(self.groupsunique.astype(str), 0, ''))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'95.0% Confidence Intervals of the Mean'}>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_means = {\n",
    "    'Decision Tree':DecisionTreeMeans2,\n",
    "    'Random Forest':RandomForestMeans2,\n",
    "    'Decision Stump':DecisionStumpMeans2,\n",
    "    'Pruned Decision Tree':prunedDecisionTreeMeans2\n",
    "}\n",
    "\n",
    "data = pd.DataFrame (model_means, columns = ['Decision Tree', 'Random Forest', 'Decision Stump', 'Pruned Decision Tree'])\n",
    "print(data)\n",
    "results = autorank(data, verbose=False)\n",
    "print(results)\n",
    "create_report(results)\n",
    "plot_stats(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e360275-9b19-4613-8014-de6ac60ece8d",
   "metadata": {},
   "source": [
    "TASK 5\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f571e-8a92-415f-bb44-7b6f859e4314",
   "metadata": {},
   "source": [
    "Adding multiplicative noise to the dataset and re-training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5961dfab-6949-44ec-8c7b-8c2724808d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08026335 -3.78228771 -0.1981627  ... -0.21858487 -0.82182924\n",
      "  -1.09646803]\n",
      " [ 0.28409008 -1.39298523  0.06080404 ... -0.85236658  3.01202697\n",
      "  -1.93137658]\n",
      " [ 2.9120361   0.34562728 -0.5801672  ...  0.43829689 -0.27263571\n",
      "  -1.33377033]\n",
      " ...\n",
      " [ 2.52567401 -1.97766863  0.36593886 ...  0.53515231  1.75158999\n",
      "  -3.10798893]\n",
      " [-2.81439771 -2.53916807  0.25360229 ...  0.92730587 -2.6612045\n",
      "  -1.86935478]\n",
      " [-2.36629631 -1.71184998 -0.24566499 ... -2.70428746  2.94678672\n",
      "  -0.99847129]]\n"
     ]
    }
   ],
   "source": [
    "multNoise = np.random.normal(1, 0.2, np.shape(newX))\n",
    "\n",
    "xMultiNoise = np.multiply(newX, multNoise)\n",
    "\n",
    "print(xMultiNoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed7923-933d-48e1-a180-d5d8e230a528",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "DECISION TREE + MULTIPLICATIVE NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3386fb4-a7b6-4d4c-aea3-7eec26e07ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 63.000%\n",
      "\n",
      "CV score:  0.6300000000000001 \n",
      "\n",
      "Decision Tree Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 61.700%\n",
      "\n",
      "CV score:  0.617 \n",
      "\n",
      "Decision Tree Accuracy:  0.595\n",
      "StratifiedKFold Mean test accuracy: 62.000%\n",
      "\n",
      "CV score:  0.62 \n",
      "\n",
      "Decision Tree Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 62.600%\n",
      "\n",
      "CV score:  0.626 \n",
      "\n",
      "Decision Tree Accuracy:  0.645\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Tree Accuracy:  0.605\n",
      "StratifiedKFold Mean test accuracy: 63.300%\n",
      "\n",
      "CV score:  0.633 \n",
      "\n",
      "Decision Tree Accuracy:  0.67\n",
      "StratifiedKFold Mean test accuracy: 62.200%\n",
      "\n",
      "CV score:  0.622 \n",
      "\n",
      "Decision Tree Accuracy:  0.54\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Tree Accuracy:  0.58\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Tree Accuracy:  0.605\n",
      "StratifiedKFold Mean test accuracy: 62.800%\n",
      "\n",
      "CV score:  0.628 \n",
      "\n",
      "[0.62, 0.615, 0.595, 0.575, 0.645, 0.605, 0.67, 0.54, 0.58, 0.605]\n",
      "Decision Tree mean score for the dataset is:  0.6050000000000001\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "DecisionTreeCVMeans = []\n",
    "DecisionTreeMeans3 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(xMultiNoise, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    decisionTree = DecisionTreeClassifier(random_state= testseed)\n",
    "    decisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionTree.predict(X_test4)\n",
    "    print(\"Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionTreeMeans3.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(DecisionTreeMeans3)\n",
    "\n",
    "DecisionTreeScore = np.mean(DecisionTreeMeans3)\n",
    "\n",
    "DecisionTreeSDframe = pd.DataFrame(DecisionTreeMeans3)\n",
    "DecisionTreeSD = DecisionTreeSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Tree mean score for the dataset is: \", DecisionTreeScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98538e-2074-4676-8c48-87b548217941",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "RANDOM FOREST + MULTIPLICATIVE NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53c23ee8-7ef1-4fb1-bbfc-d6dbc9852749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.76\n",
      "StratifiedKFold Mean test accuracy: 72.000%\n",
      "\n",
      "CV score:  0.72 \n",
      "\n",
      "Random Forest Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 70.500%\n",
      "\n",
      "CV score:  0.705 \n",
      "\n",
      "Random Forest Accuracy:  0.69\n",
      "StratifiedKFold Mean test accuracy: 71.800%\n",
      "\n",
      "CV score:  0.7180000000000001 \n",
      "\n",
      "Random Forest Accuracy:  0.685\n",
      "StratifiedKFold Mean test accuracy: 70.800%\n",
      "\n",
      "CV score:  0.708 \n",
      "\n",
      "Random Forest Accuracy:  0.715\n",
      "StratifiedKFold Mean test accuracy: 72.700%\n",
      "\n",
      "CV score:  0.727 \n",
      "\n",
      "Random Forest Accuracy:  0.76\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.705\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.64\n",
      "StratifiedKFold Mean test accuracy: 72.300%\n",
      "\n",
      "CV score:  0.723 \n",
      "\n",
      "Random Forest Accuracy:  0.645\n",
      "StratifiedKFold Mean test accuracy: 72.200%\n",
      "\n",
      "CV score:  0.722 \n",
      "\n",
      "Random Forest Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 72.100%\n",
      "\n",
      "CV score:  0.7209999999999999 \n",
      "\n",
      "[0.76, 0.72, 0.69, 0.685, 0.715, 0.76, 0.705, 0.64, 0.645, 0.72]\n",
      "Random Forest mean score for the dataset is:  0.704\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(random_state = seed)\n",
    "\n",
    "RandomForestCVMeans = []\n",
    "RandomForestMeans3 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(xMultiNoise, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    randomForest = RandomForestClassifier(random_state= testseed)\n",
    "    randomForest.fit(X_train4, y_train4.ravel())\n",
    "    predicted = randomForest.predict(X_test4)\n",
    "    print(\"Random Forest Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    RandomForestMeans3.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(randomForest, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    RandomForestCVMeans.append(score)\n",
    "    \n",
    "print(RandomForestMeans3)\n",
    "\n",
    "RandomForestScore = np.mean(RandomForestMeans3)\n",
    "\n",
    "RandomForestSDframe = pd.DataFrame(RandomForestMeans3)\n",
    "RandomForestSD = RandomForestSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Random Forest mean score for the dataset is: \", RandomForestScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60746a38-11ed-4490-bd73-5f66910fe554",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "DECISION STUMP + MULTIPLICATIVE NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "709760d2-64f8-4903-873a-9c4e42046a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Stump Accuracy:  0.65\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Stump Accuracy:  0.6\n",
      "StratifiedKFold Mean test accuracy: 61.300%\n",
      "\n",
      "CV score:  0.613 \n",
      "\n",
      "Decision Stump Accuracy:  0.58\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Stump Accuracy:  0.535\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.592 \n",
      "\n",
      "Decision Stump Accuracy:  0.6\n",
      "StratifiedKFold Mean test accuracy: 60.800%\n",
      "\n",
      "CV score:  0.6079999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.585\n",
      "StratifiedKFold Mean test accuracy: 60.300%\n",
      "\n",
      "CV score:  0.603 \n",
      "\n",
      "Decision Stump Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Stump Accuracy:  0.555\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.589 \n",
      "\n",
      "Decision Stump Accuracy:  0.535\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.5919999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.57\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.5890000000000001 \n",
      "\n",
      "[0.65, 0.6, 0.58, 0.535, 0.6, 0.585, 0.615, 0.555, 0.535, 0.57]\n",
      "Decision Stump mean score for the dataset is:  0.5825000000000001\n"
     ]
    }
   ],
   "source": [
    "decisionStump = DecisionTreeClassifier(max_depth=1,random_state = seed)\n",
    "\n",
    "DecisionStumpCVMeans = []\n",
    "DecisionStumpMeans3 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(xMultiNoise, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    decisionStump = DecisionTreeClassifier(max_depth=1,random_state = testseed)\n",
    "    decisionStump.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionStump.predict(X_test4)\n",
    "    print(\"Decision Stump Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionStumpMeans3.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionStump, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionStumpCVMeans.append(score)\n",
    "    \n",
    "print(DecisionStumpMeans3)\n",
    "\n",
    "DecisionStumpScore = np.mean(DecisionStumpMeans3)\n",
    "\n",
    "DecisionStumpframe = pd.DataFrame(DecisionStumpMeans3)\n",
    "DecisionStumpSD = DecisionStumpframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Stump mean score for the dataset is: \", DecisionStumpScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef2e9d-c3b7-4e14-8fe7-327f0ccb8342",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "PRUNED DECISION TREE + MULTIPLICATIVE NOISE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5981a6ea-a871-4479-821f-92d19218fcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008067019785769798\n",
      "Pruned Decision Tree Accuracy:  0.665\n",
      "StratifiedKFold Mean test accuracy: 65.200%\n",
      "\n",
      "CV score:  0.6519999999999999 \n",
      "\n",
      "0.006562500000000001\n",
      "Pruned Decision Tree Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 67.800%\n",
      "\n",
      "CV score:  0.6779999999999999 \n",
      "\n",
      "0.00475083918217882\n",
      "Pruned Decision Tree Accuracy:  0.635\n",
      "StratifiedKFold Mean test accuracy: 67.900%\n",
      "\n",
      "CV score:  0.679 \n",
      "\n",
      "0.003255208333333333\n",
      "Pruned Decision Tree Accuracy:  0.6\n",
      "StratifiedKFold Mean test accuracy: 65.000%\n",
      "\n",
      "CV score:  0.65 \n",
      "\n",
      "0.007212547572367663\n",
      "Pruned Decision Tree Accuracy:  0.685\n",
      "StratifiedKFold Mean test accuracy: 68.200%\n",
      "\n",
      "CV score:  0.682 \n",
      "\n",
      "0.008052445323783436\n",
      "Pruned Decision Tree Accuracy:  0.645\n",
      "StratifiedKFold Mean test accuracy: 67.500%\n",
      "\n",
      "CV score:  0.675 \n",
      "\n",
      "0.002666666666666667\n",
      "Pruned Decision Tree Accuracy:  0.645\n",
      "StratifiedKFold Mean test accuracy: 65.900%\n",
      "\n",
      "CV score:  0.659 \n",
      "\n",
      "0.005834292763157896\n",
      "Pruned Decision Tree Accuracy:  0.52\n",
      "StratifiedKFold Mean test accuracy: 67.100%\n",
      "\n",
      "CV score:  0.6709999999999999 \n",
      "\n",
      "0.00953731559299973\n",
      "Pruned Decision Tree Accuracy:  0.655\n",
      "StratifiedKFold Mean test accuracy: 64.800%\n",
      "\n",
      "CV score:  0.6479999999999999 \n",
      "\n",
      "0.004265672396359957\n",
      "Pruned Decision Tree Accuracy:  0.645\n",
      "StratifiedKFold Mean test accuracy: 68.500%\n",
      "\n",
      "CV score:  0.685 \n",
      "\n",
      "[0.665, 0.615, 0.635, 0.6, 0.685, 0.645, 0.645, 0.52, 0.655, 0.645]\n",
      "Pruned Decision Tree mean score for the dataset is:  0.631\n"
     ]
    }
   ],
   "source": [
    "prunedDecisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "prunedDecisionTreeCVMeans = []\n",
    "prunedDecisionTreeMeans3 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(xMultiNoise, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    X_train4VAL, X_val, y_train4VAL, y_val = train_test_split(X_train4, y_train4, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    treePath = DecisionTreeClassifier(random_state=testseed).cost_complexity_pruning_path(X_train4VAL, y_train4VAL)\n",
    "    \n",
    "    accuracyScores = []\n",
    "    \n",
    "    for i in treePath.ccp_alphas:\n",
    "        accuracyScores.append(DecisionTreeClassifier(ccp_alpha=i, random_state=testseed).fit(X_train4VAL, y_train4VAL).score(X_val, y_val))\n",
    "        \n",
    "    bestAlphaValue = treePath.ccp_alphas[np.argmax(accuracyScores)]\n",
    "    print(bestAlphaValue)\n",
    "    \n",
    "    prunedDecisionTree = DecisionTreeClassifier(ccp_alpha=bestAlphaValue, random_state = testseed)\n",
    "    prunedDecisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = prunedDecisionTree.predict(X_test4)\n",
    "    print(\"Pruned Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    prunedDecisionTreeMeans3.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(prunedDecisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    prunedDecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(prunedDecisionTreeMeans3)\n",
    "\n",
    "prunedDecisionTreeScore = np.mean(prunedDecisionTreeMeans3)\n",
    "\n",
    "prunedDecisionTreeframe = pd.DataFrame(prunedDecisionTreeMeans3)\n",
    "prunedDecisionTreeSD = prunedDecisionTreeframe.std()\n",
    "\n",
    "\n",
    "print(\"Pruned Decision Tree mean score for the dataset is: \", prunedDecisionTreeScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9c5ee09-c098-4e2d-8035-541be9ee6662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Decision Tree  Random Forest  Decision Stump  Pruned Decision Tree\n",
      "0          0.620          0.760           0.650                 0.665\n",
      "1          0.615          0.720           0.600                 0.615\n",
      "2          0.595          0.690           0.580                 0.635\n",
      "3          0.575          0.685           0.535                 0.600\n",
      "4          0.645          0.715           0.600                 0.685\n",
      "5          0.605          0.760           0.585                 0.645\n",
      "6          0.670          0.705           0.615                 0.645\n",
      "7          0.540          0.640           0.555                 0.520\n",
      "8          0.580          0.645           0.535                 0.655\n",
      "9          0.605          0.720           0.570                 0.645\n",
      "RankResult(rankdf=\n",
      "                      meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "Random Forest             1.10  0.7040  0.040879  0.679933  0.728067   \n",
      "Pruned Decision Tree      2.25  0.6310  0.045692  0.606933  0.655067   \n",
      "Decision Tree             2.95  0.6050  0.036515  0.580933  0.629067   \n",
      "Decision Stump            3.70  0.5825  0.035998  0.558433  0.606567   \n",
      "\n",
      "                     effect_size   magnitude  \n",
      "Random Forest                0.0  negligible  \n",
      "Pruned Decision Tree    1.683868       large  \n",
      "Decision Tree           2.554278       large  \n",
      "Decision Stump          3.154544       large  \n",
      "pvalue=1.1260812396556989e-10\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.9813687205314636, 0.4473761022090912, 0.7886638641357422, 0.04776734486222267]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.8837936321031828\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=10\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "The statistical analysis was conducted for 4 populations with 10 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=0.048). Therefore, we assume that all populations are normal.\n",
      "We applied Bartlett's test for homogeneity and failed to reject the null hypothesis (p=0.884) that the data is homoscedastic. Thus, we assume that our data is homoscedastic.\n",
      "Because we have more than two populations and all populations are normal and homoscedastic, we use repeated measures ANOVA as omnibus test to determine if there are any significant differences between the mean values of the populations. If the results of the ANOVA test are significant, we use the post-hoc Tukey HSD test to infer which differences are significant. We report the mean value (M) and the standard deviation (SD) for each population. Populations are significantly different if their confidence intervals are not overlapping.\n",
      "We reject the null hypothesis (p=0.000) of the repeated measures ANOVA that there is a difference between the mean values of the populations Random Forest (M=0.704+-0.024, SD=0.041), Pruned Decision Tree (M=0.631+-0.024, SD=0.046), Decision Tree (M=0.605+-0.024, SD=0.037), and Decision Stump (M=0.583+-0.024, SD=0.036). Therefore, we assume that there is a statistically significant difference between the mean values of the populations.\n",
      "Based post-hoc Tukey HSD test, we assume that there are no significant differences within the following groups: Decision Tree and Decision Stump. All other differences are significant.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\sandbox\\stats\\multicomp.py:775: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax1.set_yticklabels(np.insert(self.groupsunique.astype(str), 0, ''))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'95.0% Confidence Intervals of the Mean'}>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_means = {\n",
    "    'Decision Tree':DecisionTreeMeans3,\n",
    "    'Random Forest':RandomForestMeans3,\n",
    "    'Decision Stump':DecisionStumpMeans3,\n",
    "    'Pruned Decision Tree':prunedDecisionTreeMeans3\n",
    "}\n",
    "\n",
    "data = pd.DataFrame (model_means, columns = ['Decision Tree', 'Random Forest', 'Decision Stump', 'Pruned Decision Tree'])\n",
    "print(data)\n",
    "results = autorank(data, verbose=False)\n",
    "print(results)\n",
    "create_report(results)\n",
    "plot_stats(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439866a-b466-42ef-a3d5-ca4b5a956ef2",
   "metadata": {},
   "source": [
    "TASK 6\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154bd0d-0e17-45b2-ae52-bbacde34c645",
   "metadata": {},
   "source": [
    "Adding 5% class noise to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d047c00-f643-46db-b30f-35f51b5140ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "random = np.random.default_rng()\n",
    "\n",
    "flipping = random.binomial(1, 0.05, y.shape).astype(bool)\n",
    "yFlipped = np.where(flipping, 1 - y, y)\n",
    "\n",
    "newFlipping = list(chain.from_iterable(flipping))\n",
    "newFlippingArray = np.asarray(newFlipping)\n",
    "\n",
    "newY = list(chain.from_iterable(y))\n",
    "newYArray = np.asarray(newY)\n",
    "\n",
    "newYFlipped = list(chain.from_iterable(yFlipped))\n",
    "newYFlippedArray = np.asarray(newYFlipped)\n",
    "\n",
    "print(np.c_[newYArray, newYFlippedArray][newFlippingArray])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea16a8a-924d-4931-a003-7998ee539b4c",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "DECISION TREE + 5% CLASS NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e049252-0537-4b27-b47b-32d29845b70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.655\n",
      "StratifiedKFold Mean test accuracy: 63.000%\n",
      "\n",
      "CV score:  0.6300000000000001 \n",
      "\n",
      "Decision Tree Accuracy:  0.585\n",
      "StratifiedKFold Mean test accuracy: 61.700%\n",
      "\n",
      "CV score:  0.617 \n",
      "\n",
      "Decision Tree Accuracy:  0.585\n",
      "StratifiedKFold Mean test accuracy: 62.000%\n",
      "\n",
      "CV score:  0.62 \n",
      "\n",
      "Decision Tree Accuracy:  0.595\n",
      "StratifiedKFold Mean test accuracy: 62.600%\n",
      "\n",
      "CV score:  0.626 \n",
      "\n",
      "Decision Tree Accuracy:  0.595\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Tree Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 63.300%\n",
      "\n",
      "CV score:  0.633 \n",
      "\n",
      "Decision Tree Accuracy:  0.635\n",
      "StratifiedKFold Mean test accuracy: 62.200%\n",
      "\n",
      "CV score:  0.622 \n",
      "\n",
      "Decision Tree Accuracy:  0.565\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Tree Accuracy:  0.57\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Tree Accuracy:  0.63\n",
      "StratifiedKFold Mean test accuracy: 62.800%\n",
      "\n",
      "CV score:  0.628 \n",
      "\n",
      "[0.655, 0.585, 0.585, 0.595, 0.595, 0.575, 0.635, 0.565, 0.57, 0.63]\n",
      "Decision Tree mean score for the dataset is:  0.599\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "DecisionTreeCVMeans = []\n",
    "DecisionTreeMeans4 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, newYFlippedArray, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    decisionTree = DecisionTreeClassifier(random_state= testseed)\n",
    "    decisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionTree.predict(X_test4)\n",
    "    print(\"Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionTreeMeans4.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(DecisionTreeMeans4)\n",
    "\n",
    "DecisionTreeScore = np.mean(DecisionTreeMeans4)\n",
    "\n",
    "DecisionTreeSDframe = pd.DataFrame(DecisionTreeMeans4)\n",
    "DecisionTreeSD = DecisionTreeSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Tree mean score for the dataset is: \", DecisionTreeScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d650d62c-f734-42d0-b3d3-620f81b22258",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "RANDOM FOREST + 5% CLASS NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f698680-8b03-4b39-82c6-367bff49f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.705\n",
      "StratifiedKFold Mean test accuracy: 72.000%\n",
      "\n",
      "CV score:  0.72 \n",
      "\n",
      "Random Forest Accuracy:  0.71\n",
      "StratifiedKFold Mean test accuracy: 70.500%\n",
      "\n",
      "CV score:  0.705 \n",
      "\n",
      "Random Forest Accuracy:  0.635\n",
      "StratifiedKFold Mean test accuracy: 71.800%\n",
      "\n",
      "CV score:  0.7180000000000001 \n",
      "\n",
      "Random Forest Accuracy:  0.695\n",
      "StratifiedKFold Mean test accuracy: 70.800%\n",
      "\n",
      "CV score:  0.708 \n",
      "\n",
      "Random Forest Accuracy:  0.68\n",
      "StratifiedKFold Mean test accuracy: 72.700%\n",
      "\n",
      "CV score:  0.727 \n",
      "\n",
      "Random Forest Accuracy:  0.68\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.675\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.68\n",
      "StratifiedKFold Mean test accuracy: 72.300%\n",
      "\n",
      "CV score:  0.723 \n",
      "\n",
      "Random Forest Accuracy:  0.65\n",
      "StratifiedKFold Mean test accuracy: 72.200%\n",
      "\n",
      "CV score:  0.722 \n",
      "\n",
      "Random Forest Accuracy:  0.67\n",
      "StratifiedKFold Mean test accuracy: 72.100%\n",
      "\n",
      "CV score:  0.7209999999999999 \n",
      "\n",
      "[0.705, 0.71, 0.635, 0.695, 0.68, 0.68, 0.675, 0.68, 0.65, 0.67]\n",
      "Random Forest mean score for the dataset is:  0.678\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(random_state = seed)\n",
    "\n",
    "RandomForestCVMeans = []\n",
    "RandomForestMeans4 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, newYFlippedArray, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    randomForest = RandomForestClassifier(random_state= testseed)\n",
    "    randomForest.fit(X_train4, y_train4.ravel())\n",
    "    predicted = randomForest.predict(X_test4)\n",
    "    print(\"Random Forest Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    RandomForestMeans4.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(randomForest, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    RandomForestCVMeans.append(score)\n",
    "    \n",
    "print(RandomForestMeans4)\n",
    "\n",
    "RandomForestScore = np.mean(RandomForestMeans4)\n",
    "\n",
    "RandomForestSDframe = pd.DataFrame(RandomForestMeans4)\n",
    "RandomForestSD = RandomForestSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Random Forest mean score for the dataset is: \", RandomForestScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b2f877-ff8e-4645-865b-a312638757e6",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "DECISION STUMP + 5% CLASS NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2aa659f7-afa8-4909-b532-3b2cf1748528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Stump Accuracy:  0.605\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Stump Accuracy:  0.57\n",
      "StratifiedKFold Mean test accuracy: 61.300%\n",
      "\n",
      "CV score:  0.613 \n",
      "\n",
      "Decision Stump Accuracy:  0.555\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Stump Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.592 \n",
      "\n",
      "Decision Stump Accuracy:  0.6\n",
      "StratifiedKFold Mean test accuracy: 60.800%\n",
      "\n",
      "CV score:  0.6079999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 60.300%\n",
      "\n",
      "CV score:  0.603 \n",
      "\n",
      "Decision Stump Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Stump Accuracy:  0.585\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.589 \n",
      "\n",
      "Decision Stump Accuracy:  0.525\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.5919999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.5890000000000001 \n",
      "\n",
      "[0.605, 0.57, 0.555, 0.615, 0.6, 0.575, 0.615, 0.585, 0.525, 0.575]\n",
      "Decision Stump mean score for the dataset is:  0.5820000000000001\n"
     ]
    }
   ],
   "source": [
    "decisionStump = DecisionTreeClassifier(max_depth=1,random_state = seed)\n",
    "\n",
    "DecisionStumpCVMeans = []\n",
    "DecisionStumpMeans4 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, newYFlippedArray, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    decisionStump = DecisionTreeClassifier(max_depth=1,random_state = testseed)\n",
    "    decisionStump.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionStump.predict(X_test4)\n",
    "    print(\"Decision Stump Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionStumpMeans4.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionStump, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionStumpCVMeans.append(score)\n",
    "    \n",
    "print(DecisionStumpMeans4)\n",
    "\n",
    "DecisionStumpScore = np.mean(DecisionStumpMeans4)\n",
    "\n",
    "DecisionStumpframe = pd.DataFrame(DecisionStumpMeans4)\n",
    "DecisionStumpSD = DecisionStumpframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Stump mean score for the dataset is: \", DecisionStumpScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588d915-9337-4fe6-b9ea-13b4df1fe1b1",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "PRUNED DECISION TREE + 5% CLASS NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26f77a5e-0c7b-4e34-8669-1fdfd23c10df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039776445637119184\n",
      "Pruned Decision Tree Accuracy:  0.5\n",
      "StratifiedKFold Mean test accuracy: 51.400%\n",
      "\n",
      "CV score:  0.514 \n",
      "\n",
      "0.002604166666666667\n",
      "Pruned Decision Tree Accuracy:  0.585\n",
      "StratifiedKFold Mean test accuracy: 65.200%\n",
      "\n",
      "CV score:  0.652 \n",
      "\n",
      "0.004961638131414177\n",
      "Pruned Decision Tree Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 67.100%\n",
      "\n",
      "CV score:  0.671 \n",
      "\n",
      "0.006845190779014309\n",
      "Pruned Decision Tree Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 65.000%\n",
      "\n",
      "CV score:  0.65 \n",
      "\n",
      "0.00881857230667262\n",
      "Pruned Decision Tree Accuracy:  0.635\n",
      "StratifiedKFold Mean test accuracy: 67.200%\n",
      "\n",
      "CV score:  0.672 \n",
      "\n",
      "0.01243593740576776\n",
      "Pruned Decision Tree Accuracy:  0.605\n",
      "StratifiedKFold Mean test accuracy: 66.000%\n",
      "\n",
      "CV score:  0.6599999999999999 \n",
      "\n",
      "0.0025950292397660824\n",
      "Pruned Decision Tree Accuracy:  0.655\n",
      "StratifiedKFold Mean test accuracy: 65.700%\n",
      "\n",
      "CV score:  0.6569999999999999 \n",
      "\n",
      "0.013749240163572096\n",
      "Pruned Decision Tree Accuracy:  0.58\n",
      "StratifiedKFold Mean test accuracy: 64.300%\n",
      "\n",
      "CV score:  0.643 \n",
      "\n",
      "0.0067709714854111425\n",
      "Pruned Decision Tree Accuracy:  0.625\n",
      "StratifiedKFold Mean test accuracy: 68.400%\n",
      "\n",
      "CV score:  0.6839999999999999 \n",
      "\n",
      "0.0\n",
      "Pruned Decision Tree Accuracy:  0.63\n",
      "StratifiedKFold Mean test accuracy: 62.800%\n",
      "\n",
      "CV score:  0.628 \n",
      "\n",
      "[0.5, 0.585, 0.615, 0.62, 0.635, 0.605, 0.655, 0.58, 0.625, 0.63]\n",
      "Pruned Decision Tree mean score for the dataset is:  0.605\n"
     ]
    }
   ],
   "source": [
    "prunedDecisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "prunedDecisionTreeCVMeans = []\n",
    "prunedDecisionTreeMeans4 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, newYFlippedArray, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    X_train4VAL, X_val, y_train4VAL, y_val = train_test_split(X_train4, y_train4, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    treePath = DecisionTreeClassifier(random_state=testseed).cost_complexity_pruning_path(X_train4VAL, y_train4VAL)\n",
    "    \n",
    "    accuracyScores = []\n",
    "    \n",
    "    for i in treePath.ccp_alphas:\n",
    "        accuracyScores.append(DecisionTreeClassifier(ccp_alpha=i, random_state=testseed).fit(X_train4VAL, y_train4VAL).score(X_val, y_val))\n",
    "        \n",
    "    bestAlphaValue = treePath.ccp_alphas[np.argmax(accuracyScores)]\n",
    "    print(bestAlphaValue)\n",
    "    \n",
    "    prunedDecisionTree = DecisionTreeClassifier(ccp_alpha=bestAlphaValue, random_state = testseed)\n",
    "    prunedDecisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = prunedDecisionTree.predict(X_test4)\n",
    "    print(\"Pruned Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    prunedDecisionTreeMeans4.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(prunedDecisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    prunedDecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(prunedDecisionTreeMeans4)\n",
    "\n",
    "prunedDecisionTreeScore = np.mean(prunedDecisionTreeMeans4)\n",
    "\n",
    "prunedDecisionTreeframe = pd.DataFrame(prunedDecisionTreeMeans4)\n",
    "prunedDecisionTreeSD = prunedDecisionTreeframe.std()\n",
    "\n",
    "\n",
    "print(\"Pruned Decision Tree mean score for the dataset is: \", prunedDecisionTreeScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f94ab65b-001d-4e7a-86af-1f7db470f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Decision Tree  Random Forest  Decision Stump  Pruned Decision Tree\n",
      "0          0.655          0.705           0.605                 0.500\n",
      "1          0.585          0.710           0.570                 0.585\n",
      "2          0.585          0.635           0.555                 0.615\n",
      "3          0.595          0.695           0.615                 0.620\n",
      "4          0.595          0.680           0.600                 0.635\n",
      "5          0.575          0.680           0.575                 0.605\n",
      "6          0.635          0.675           0.615                 0.655\n",
      "7          0.565          0.680           0.585                 0.580\n",
      "8          0.570          0.650           0.525                 0.625\n",
      "9          0.630          0.670           0.575                 0.630\n",
      "RankResult(rankdf=\n",
      "                      meanrank   mean       std  ci_lower  ci_upper  \\\n",
      "Random Forest             1.00  0.678  0.022998  0.658638  0.697362   \n",
      "Pruned Decision Tree      2.40  0.605  0.043205  0.585638  0.624362   \n",
      "Decision Tree             3.15  0.599  0.030532  0.579638  0.618362   \n",
      "Decision Stump            3.45  0.582  0.028402  0.562638  0.601362   \n",
      "\n",
      "                     effect_size   magnitude  \n",
      "Random Forest                0.0  negligible  \n",
      "Pruned Decision Tree    2.109282       large  \n",
      "Decision Tree           2.922809       large  \n",
      "Decision Stump          3.714969       large  \n",
      "pvalue=1.434905410801341e-06\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.17167146503925323, 0.6183730959892273, 0.4882594048976898, 0.05419781804084778]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.29579445584637315\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=10\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "The statistical analysis was conducted for 4 populations with 10 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=0.054). Therefore, we assume that all populations are normal.\n",
      "We applied Bartlett's test for homogeneity and failed to reject the null hypothesis (p=0.296) that the data is homoscedastic. Thus, we assume that our data is homoscedastic.\n",
      "Because we have more than two populations and all populations are normal and homoscedastic, we use repeated measures ANOVA as omnibus test to determine if there are any significant differences between the mean values of the populations. If the results of the ANOVA test are significant, we use the post-hoc Tukey HSD test to infer which differences are significant. We report the mean value (M) and the standard deviation (SD) for each population. Populations are significantly different if their confidence intervals are not overlapping.\n",
      "We reject the null hypothesis (p=0.000) of the repeated measures ANOVA that there is a difference between the mean values of the populations Random Forest (M=0.678+-0.019, SD=0.023), Pruned Decision Tree (M=0.605+-0.019, SD=0.043), Decision Tree (M=0.599+-0.019, SD=0.031), and Decision Stump (M=0.582+-0.019, SD=0.028). Therefore, we assume that there is a statistically significant difference between the mean values of the populations.\n",
      "Based post-hoc Tukey HSD test, we assume that there are no significant differences within the following groups: Pruned Decision Tree and Decision Tree; Decision Tree and Decision Stump. All other differences are significant.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\sandbox\\stats\\multicomp.py:775: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax1.set_yticklabels(np.insert(self.groupsunique.astype(str), 0, ''))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'95.0% Confidence Intervals of the Mean'}>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_means = {\n",
    "    'Decision Tree':DecisionTreeMeans4,\n",
    "    'Random Forest':RandomForestMeans4,\n",
    "    'Decision Stump':DecisionStumpMeans4,\n",
    "    'Pruned Decision Tree':prunedDecisionTreeMeans4\n",
    "}\n",
    "\n",
    "data = pd.DataFrame (model_means, columns = ['Decision Tree', 'Random Forest', 'Decision Stump', 'Pruned Decision Tree'])\n",
    "print(data)\n",
    "results = autorank(data, verbose=False)\n",
    "print(results)\n",
    "create_report(results)\n",
    "plot_stats(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a02e4-8846-4b63-a500-e2f480092467",
   "metadata": {},
   "source": [
    "TASK 7\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1eead-db6b-4d02-8d90-a4a716cb2d64",
   "metadata": {},
   "source": [
    "## MODELS WITH TRAINING SET NOISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e507ffa-dfc4-4385-be4b-cad6d0f3b8f2",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "DECISION TREE + TRAINING SET NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ee27a93-8300-45b7-98c8-c34cd6480284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.655\n",
      "StratifiedKFold Mean test accuracy: 63.000%\n",
      "\n",
      "CV score:  0.6300000000000001 \n",
      "\n",
      "Decision Tree Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 61.700%\n",
      "\n",
      "CV score:  0.617 \n",
      "\n",
      "Decision Tree Accuracy:  0.59\n",
      "StratifiedKFold Mean test accuracy: 62.000%\n",
      "\n",
      "CV score:  0.62 \n",
      "\n",
      "Decision Tree Accuracy:  0.64\n",
      "StratifiedKFold Mean test accuracy: 62.600%\n",
      "\n",
      "CV score:  0.626 \n",
      "\n",
      "Decision Tree Accuracy:  0.56\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Tree Accuracy:  0.61\n",
      "StratifiedKFold Mean test accuracy: 63.300%\n",
      "\n",
      "CV score:  0.633 \n",
      "\n",
      "Decision Tree Accuracy:  0.615\n",
      "StratifiedKFold Mean test accuracy: 62.200%\n",
      "\n",
      "CV score:  0.622 \n",
      "\n",
      "Decision Tree Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Tree Accuracy:  0.565\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Tree Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 62.800%\n",
      "\n",
      "CV score:  0.628 \n",
      "\n",
      "[0.655, 0.615, 0.59, 0.64, 0.56, 0.61, 0.615, 0.62, 0.565, 0.62]\n",
      "Decision Tree mean score for the dataset is:  0.6089999999999999\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "DecisionTreeCVMeans = []\n",
    "DecisionTreeMeans5 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    multNoise = np.random.normal(1, 0.2, np.shape(X_train4))\n",
    "\n",
    "    xMultiNoise = np.multiply(X_train4, multNoise)\n",
    "\n",
    "    decisionTree = DecisionTreeClassifier(random_state= testseed)\n",
    "    decisionTree.fit(xMultiNoise, y_train4.ravel())\n",
    "    predicted = decisionTree.predict(X_test4)\n",
    "    print(\"Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionTreeMeans5.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(DecisionTreeMeans5)\n",
    "\n",
    "DecisionTreeScore = np.mean(DecisionTreeMeans5)\n",
    "\n",
    "DecisionTreeSDframe = pd.DataFrame(DecisionTreeMeans5)\n",
    "DecisionTreeSD = DecisionTreeSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Tree mean score for the dataset is: \", DecisionTreeScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5fbc0-b4fd-4e94-b9c7-a47dbdd31114",
   "metadata": {},
   "source": [
    "RANDOM FOREST + TRAINING SET NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4b93153-38c4-4ba1-a87f-404ce9c1adc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.725\n",
      "StratifiedKFold Mean test accuracy: 72.000%\n",
      "\n",
      "CV score:  0.72 \n",
      "\n",
      "Random Forest Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 70.500%\n",
      "\n",
      "CV score:  0.705 \n",
      "\n",
      "Random Forest Accuracy:  0.69\n",
      "StratifiedKFold Mean test accuracy: 71.800%\n",
      "\n",
      "CV score:  0.7180000000000001 \n",
      "\n",
      "Random Forest Accuracy:  0.69\n",
      "StratifiedKFold Mean test accuracy: 70.800%\n",
      "\n",
      "CV score:  0.708 \n",
      "\n",
      "Random Forest Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 72.700%\n",
      "\n",
      "CV score:  0.727 \n",
      "\n",
      "Random Forest Accuracy:  0.73\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.71\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.675\n",
      "StratifiedKFold Mean test accuracy: 72.300%\n",
      "\n",
      "CV score:  0.723 \n",
      "\n",
      "Random Forest Accuracy:  0.68\n",
      "StratifiedKFold Mean test accuracy: 72.200%\n",
      "\n",
      "CV score:  0.722 \n",
      "\n",
      "Random Forest Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 72.100%\n",
      "\n",
      "CV score:  0.7209999999999999 \n",
      "\n",
      "[0.725, 0.7, 0.69, 0.69, 0.7, 0.73, 0.71, 0.675, 0.68, 0.7]\n",
      "Random Forest mean score for the dataset is:  0.7\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(random_state = seed)\n",
    "\n",
    "RandomForestCVMeans = []\n",
    "RandomForestMeans5 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    multNoise = np.random.normal(1, 0.2, np.shape(X_train4))\n",
    "\n",
    "    xMultiNoise = np.multiply(X_train4, multNoise)\n",
    "    \n",
    "    randomForest = RandomForestClassifier(random_state= testseed)\n",
    "    randomForest.fit(xMultiNoise, y_train4.ravel())\n",
    "    predicted = randomForest.predict(X_test4)\n",
    "    print(\"Random Forest Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    RandomForestMeans5.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(randomForest, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    RandomForestCVMeans.append(score)\n",
    "    \n",
    "print(RandomForestMeans5)\n",
    "\n",
    "RandomForestScore = np.mean(RandomForestMeans5)\n",
    "\n",
    "RandomForestSDframe = pd.DataFrame(RandomForestMeans5)\n",
    "RandomForestSD = RandomForestSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Random Forest mean score for the dataset is: \", RandomForestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "596c25ba-be5c-40b4-b9f8-4cbbcbe95c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Stump Accuracy:  0.645\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Stump Accuracy:  0.585\n",
      "StratifiedKFold Mean test accuracy: 61.300%\n",
      "\n",
      "CV score:  0.613 \n",
      "\n",
      "Decision Stump Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Stump Accuracy:  0.64\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.592 \n",
      "\n",
      "Decision Stump Accuracy:  0.665\n",
      "StratifiedKFold Mean test accuracy: 60.800%\n",
      "\n",
      "CV score:  0.6079999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.585\n",
      "StratifiedKFold Mean test accuracy: 60.300%\n",
      "\n",
      "CV score:  0.603 \n",
      "\n",
      "Decision Stump Accuracy:  0.635\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Stump Accuracy:  0.555\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.589 \n",
      "\n",
      "Decision Stump Accuracy:  0.53\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.5919999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.5890000000000001 \n",
      "\n",
      "[0.645, 0.585, 0.575, 0.64, 0.665, 0.585, 0.635, 0.555, 0.53, 0.575]\n",
      "Decision Stump mean score for the dataset is:  0.599\n"
     ]
    }
   ],
   "source": [
    "decisionStump = DecisionTreeClassifier(max_depth=1,random_state = seed)\n",
    "\n",
    "DecisionStumpCVMeans = []\n",
    "DecisionStumpMeans5 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    multNoise = np.random.normal(1, 0.2, np.shape(X_train4))\n",
    "\n",
    "    xMultiNoise = np.multiply(X_train4, multNoise)\n",
    "    \n",
    "    decisionStump = DecisionTreeClassifier(max_depth=1,random_state = testseed)\n",
    "    decisionStump.fit(xMultiNoise, y_train4.ravel())\n",
    "    predicted = decisionStump.predict(X_test4)\n",
    "    print(\"Decision Stump Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionStumpMeans5.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionStump, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionStumpCVMeans.append(score)\n",
    "    \n",
    "print(DecisionStumpMeans5)\n",
    "\n",
    "DecisionStumpScore = np.mean(DecisionStumpMeans5)\n",
    "\n",
    "DecisionStumpframe = pd.DataFrame(DecisionStumpMeans5)\n",
    "DecisionStumpSD = DecisionStumpframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Stump mean score for the dataset is: \", DecisionStumpScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bfb93ac9-93a7-4b8a-b021-54dda3151e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009077397502654058\n",
      "Pruned Decision Tree Accuracy:  0.685\n",
      "StratifiedKFold Mean test accuracy: 65.300%\n",
      "\n",
      "CV score:  0.6529999999999999 \n",
      "\n",
      "0.006977883641381716\n",
      "Pruned Decision Tree Accuracy:  0.67\n",
      "StratifiedKFold Mean test accuracy: 68.000%\n",
      "\n",
      "CV score:  0.68 \n",
      "\n",
      "0.005560088957724901\n",
      "Pruned Decision Tree Accuracy:  0.605\n",
      "StratifiedKFold Mean test accuracy: 68.400%\n",
      "\n",
      "CV score:  0.6839999999999999 \n",
      "\n",
      "0.002895220588235294\n",
      "Pruned Decision Tree Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 64.000%\n",
      "\n",
      "CV score:  0.64 \n",
      "\n",
      "0.005312881562881559\n",
      "Pruned Decision Tree Accuracy:  0.645\n",
      "StratifiedKFold Mean test accuracy: 69.700%\n",
      "\n",
      "CV score:  0.697 \n",
      "\n",
      "0.006606166490857948\n",
      "Pruned Decision Tree Accuracy:  0.69\n",
      "StratifiedKFold Mean test accuracy: 68.300%\n",
      "\n",
      "CV score:  0.683 \n",
      "\n",
      "0.016372987350972062\n",
      "Pruned Decision Tree Accuracy:  0.675\n",
      "StratifiedKFold Mean test accuracy: 64.500%\n",
      "\n",
      "CV score:  0.645 \n",
      "\n",
      "0.008402489743728772\n",
      "Pruned Decision Tree Accuracy:  0.55\n",
      "StratifiedKFold Mean test accuracy: 67.000%\n",
      "\n",
      "CV score:  0.67 \n",
      "\n",
      "0.003970588235294116\n",
      "Pruned Decision Tree Accuracy:  0.625\n",
      "StratifiedKFold Mean test accuracy: 67.500%\n",
      "\n",
      "CV score:  0.675 \n",
      "\n",
      "0.005665811567164179\n",
      "Pruned Decision Tree Accuracy:  0.67\n",
      "StratifiedKFold Mean test accuracy: 68.400%\n",
      "\n",
      "CV score:  0.6839999999999999 \n",
      "\n",
      "[0.685, 0.67, 0.605, 0.62, 0.645, 0.69, 0.675, 0.55, 0.625, 0.67]\n",
      "Pruned Decision Tree mean score for the dataset is:  0.6435000000000001\n"
     ]
    }
   ],
   "source": [
    "prunedDecisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "prunedDecisionTreeCVMeans = []\n",
    "prunedDecisionTreeMeans5 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    multNoise = np.random.normal(1, 0.2, np.shape(X_train4))\n",
    "\n",
    "    xMultiNoise = np.multiply(X_train4, multNoise)\n",
    "        \n",
    "    X_train4VAL, X_val, y_train4VAL, y_val = train_test_split(xMultiNoise, y_train4, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    treePath = DecisionTreeClassifier(random_state=testseed).cost_complexity_pruning_path(X_train4VAL, y_train4VAL)\n",
    "    \n",
    "    accuracyScores = []\n",
    "    \n",
    "    for i in treePath.ccp_alphas:\n",
    "        accuracyScores.append(DecisionTreeClassifier(ccp_alpha=i, random_state=testseed).fit(X_train4VAL, y_train4VAL).score(X_val, y_val))\n",
    "        \n",
    "    bestAlphaValue = treePath.ccp_alphas[np.argmax(accuracyScores)]\n",
    "    print(bestAlphaValue)\n",
    "    \n",
    "    prunedDecisionTree = DecisionTreeClassifier(ccp_alpha=bestAlphaValue, random_state = testseed)\n",
    "    prunedDecisionTree.fit(xMultiNoise, y_train4.ravel())\n",
    "    predicted = prunedDecisionTree.predict(X_test4)\n",
    "    print(\"Pruned Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    prunedDecisionTreeMeans5.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(prunedDecisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    prunedDecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(prunedDecisionTreeMeans5)\n",
    "\n",
    "prunedDecisionTreeScore = np.mean(prunedDecisionTreeMeans5)\n",
    "\n",
    "prunedDecisionTreeframe = pd.DataFrame(prunedDecisionTreeMeans5)\n",
    "prunedDecisionTreeSD = prunedDecisionTreeframe.std()\n",
    "\n",
    "\n",
    "print(\"Pruned Decision Tree mean score for the dataset is: \", prunedDecisionTreeScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed23345a-a786-4b33-9652-308998a0f5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Decision Tree  Random Forest  Decision Stump  Pruned Decision Tree\n",
      "0          0.655          0.725           0.645                 0.685\n",
      "1          0.615          0.700           0.585                 0.670\n",
      "2          0.590          0.690           0.575                 0.605\n",
      "3          0.640          0.690           0.640                 0.620\n",
      "4          0.560          0.700           0.665                 0.645\n",
      "5          0.610          0.730           0.585                 0.690\n",
      "6          0.615          0.710           0.635                 0.675\n",
      "7          0.620          0.675           0.555                 0.550\n",
      "8          0.565          0.680           0.530                 0.625\n",
      "9          0.620          0.700           0.575                 0.670\n",
      "RankResult(rankdf=\n",
      "                      meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "Random Forest             1.00  0.7000  0.017795  0.678465  0.721535   \n",
      "Pruned Decision Tree      2.50  0.6435  0.043973  0.621965  0.665035   \n",
      "Decision Tree             3.05  0.6090  0.029981  0.587465  0.630535   \n",
      "Decision Stump            3.45  0.5990  0.044335  0.577465  0.620535   \n",
      "\n",
      "                     effect_size   magnitude  \n",
      "Random Forest                0.0  negligible  \n",
      "Pruned Decision Tree    1.684401       large  \n",
      "Decision Tree           3.691212       large  \n",
      "Decision Stump          2.989905       large  \n",
      "pvalue=7.065858806244362e-08\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.4681871235370636, 0.5999016165733337, 0.4615441560745239, 0.20410870015621185]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.050747531888632576\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=10\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "The statistical analysis was conducted for 4 populations with 10 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=0.204). Therefore, we assume that all populations are normal.\n",
      "We applied Bartlett's test for homogeneity and failed to reject the null hypothesis (p=0.051) that the data is homoscedastic. Thus, we assume that our data is homoscedastic.\n",
      "Because we have more than two populations and all populations are normal and homoscedastic, we use repeated measures ANOVA as omnibus test to determine if there are any significant differences between the mean values of the populations. If the results of the ANOVA test are significant, we use the post-hoc Tukey HSD test to infer which differences are significant. We report the mean value (M) and the standard deviation (SD) for each population. Populations are significantly different if their confidence intervals are not overlapping.\n",
      "We reject the null hypothesis (p=0.000) of the repeated measures ANOVA that there is a difference between the mean values of the populations Random Forest (M=0.700+-0.022, SD=0.018), Pruned Decision Tree (M=0.644+-0.022, SD=0.044), Decision Tree (M=0.609+-0.022, SD=0.030), and Decision Stump (M=0.599+-0.022, SD=0.044). Therefore, we assume that there is a statistically significant difference between the mean values of the populations.\n",
      "Based post-hoc Tukey HSD test, we assume that there are no significant differences within the following groups: Decision Tree and Decision Stump. All other differences are significant.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\sandbox\\stats\\multicomp.py:775: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax1.set_yticklabels(np.insert(self.groupsunique.astype(str), 0, ''))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'95.0% Confidence Intervals of the Mean'}>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_means = {\n",
    "    'Decision Tree':DecisionTreeMeans5,\n",
    "    'Random Forest':RandomForestMeans5,\n",
    "    'Decision Stump':DecisionStumpMeans5,\n",
    "    'Pruned Decision Tree':prunedDecisionTreeMeans5\n",
    "}\n",
    "\n",
    "data = pd.DataFrame (model_means, columns = ['Decision Tree', 'Random Forest', 'Decision Stump', 'Pruned Decision Tree'])\n",
    "print(data)\n",
    "results = autorank(data, verbose=False)\n",
    "print(results)\n",
    "create_report(results)\n",
    "plot_stats(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673ca43-cb9e-4f2a-87ed-ad5587a0c314",
   "metadata": {},
   "source": [
    "## MODELS WITH TEST SET NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "544a7f66-4bcb-40ff-9aae-4ed88c06128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy:  0.68\n",
      "StratifiedKFold Mean test accuracy: 63.000%\n",
      "\n",
      "CV score:  0.6300000000000001 \n",
      "\n",
      "Decision Tree Accuracy:  0.6\n",
      "StratifiedKFold Mean test accuracy: 61.700%\n",
      "\n",
      "CV score:  0.617 \n",
      "\n",
      "Decision Tree Accuracy:  0.59\n",
      "StratifiedKFold Mean test accuracy: 62.000%\n",
      "\n",
      "CV score:  0.62 \n",
      "\n",
      "Decision Tree Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 62.600%\n",
      "\n",
      "CV score:  0.626 \n",
      "\n",
      "Decision Tree Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Tree Accuracy:  0.65\n",
      "StratifiedKFold Mean test accuracy: 63.300%\n",
      "\n",
      "CV score:  0.633 \n",
      "\n",
      "Decision Tree Accuracy:  0.645\n",
      "StratifiedKFold Mean test accuracy: 62.200%\n",
      "\n",
      "CV score:  0.622 \n",
      "\n",
      "Decision Tree Accuracy:  0.595\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Tree Accuracy:  0.64\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Tree Accuracy:  0.59\n",
      "StratifiedKFold Mean test accuracy: 62.800%\n",
      "\n",
      "CV score:  0.628 \n",
      "\n",
      "[0.68, 0.6, 0.59, 0.575, 0.575, 0.65, 0.645, 0.595, 0.64, 0.59]\n",
      "Decision Tree mean score for the dataset is:  0.614\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "DecisionTreeCVMeans = []\n",
    "DecisionTreeMeans6 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    multNoise = np.random.normal(1, 0.2, np.shape(X_test4))\n",
    "\n",
    "    xTestMultiNoise = np.multiply(X_test4, multNoise)\n",
    "\n",
    "    decisionTree = DecisionTreeClassifier(random_state= testseed)\n",
    "    decisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionTree.predict(xTestMultiNoise)\n",
    "    print(\"Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionTreeMeans6.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(DecisionTreeMeans6)\n",
    "\n",
    "DecisionTreeScore = np.mean(DecisionTreeMeans6)\n",
    "\n",
    "DecisionTreeSDframe = pd.DataFrame(DecisionTreeMeans6)\n",
    "DecisionTreeSD = DecisionTreeSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Tree mean score for the dataset is: \", DecisionTreeScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c8b8baf9-5905-45ed-8cdf-8c40cabc7152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.74\n",
      "StratifiedKFold Mean test accuracy: 72.000%\n",
      "\n",
      "CV score:  0.72 \n",
      "\n",
      "Random Forest Accuracy:  0.7\n",
      "StratifiedKFold Mean test accuracy: 70.500%\n",
      "\n",
      "CV score:  0.705 \n",
      "\n",
      "Random Forest Accuracy:  0.725\n",
      "StratifiedKFold Mean test accuracy: 71.800%\n",
      "\n",
      "CV score:  0.7180000000000001 \n",
      "\n",
      "Random Forest Accuracy:  0.66\n",
      "StratifiedKFold Mean test accuracy: 70.800%\n",
      "\n",
      "CV score:  0.708 \n",
      "\n",
      "Random Forest Accuracy:  0.735\n",
      "StratifiedKFold Mean test accuracy: 72.700%\n",
      "\n",
      "CV score:  0.727 \n",
      "\n",
      "Random Forest Accuracy:  0.72\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.68\n",
      "StratifiedKFold Mean test accuracy: 71.400%\n",
      "\n",
      "CV score:  0.714 \n",
      "\n",
      "Random Forest Accuracy:  0.66\n",
      "StratifiedKFold Mean test accuracy: 72.300%\n",
      "\n",
      "CV score:  0.723 \n",
      "\n",
      "Random Forest Accuracy:  0.69\n",
      "StratifiedKFold Mean test accuracy: 72.200%\n",
      "\n",
      "CV score:  0.722 \n",
      "\n",
      "Random Forest Accuracy:  0.685\n",
      "StratifiedKFold Mean test accuracy: 72.100%\n",
      "\n",
      "CV score:  0.7209999999999999 \n",
      "\n",
      "[0.74, 0.7, 0.725, 0.66, 0.735, 0.72, 0.68, 0.66, 0.69, 0.685]\n",
      "Random Forest mean score for the dataset is:  0.6995000000000001\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(random_state = seed)\n",
    "\n",
    "RandomForestCVMeans = []\n",
    "RandomForestMeans6 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    multNoise = np.random.normal(1, 0.2, np.shape(X_test4))\n",
    "\n",
    "    xTestMultiNoise = np.multiply(X_test4, multNoise)\n",
    "    \n",
    "    randomForest = RandomForestClassifier(random_state= testseed)\n",
    "    randomForest.fit(X_train4, y_train4.ravel())\n",
    "    predicted = randomForest.predict(xTestMultiNoise)\n",
    "    print(\"Random Forest Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    RandomForestMeans6.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(randomForest, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    RandomForestCVMeans.append(score)\n",
    "    \n",
    "print(RandomForestMeans6)\n",
    "\n",
    "RandomForestScore = np.mean(RandomForestMeans6)\n",
    "\n",
    "RandomForestSDframe = pd.DataFrame(RandomForestMeans6)\n",
    "RandomForestSD = RandomForestSDframe.std()\n",
    "\n",
    "\n",
    "print(\"Random Forest mean score for the dataset is: \", RandomForestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "205231c2-0988-41d8-bbba-06bfea19c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Stump Accuracy:  0.635\n",
      "StratifiedKFold Mean test accuracy: 61.000%\n",
      "\n",
      "CV score:  0.61 \n",
      "\n",
      "Decision Stump Accuracy:  0.58\n",
      "StratifiedKFold Mean test accuracy: 61.300%\n",
      "\n",
      "CV score:  0.613 \n",
      "\n",
      "Decision Stump Accuracy:  0.575\n",
      "StratifiedKFold Mean test accuracy: 60.700%\n",
      "\n",
      "CV score:  0.607 \n",
      "\n",
      "Decision Stump Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.592 \n",
      "\n",
      "Decision Stump Accuracy:  0.64\n",
      "StratifiedKFold Mean test accuracy: 60.800%\n",
      "\n",
      "CV score:  0.6079999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.595\n",
      "StratifiedKFold Mean test accuracy: 60.300%\n",
      "\n",
      "CV score:  0.603 \n",
      "\n",
      "Decision Stump Accuracy:  0.64\n",
      "StratifiedKFold Mean test accuracy: 60.900%\n",
      "\n",
      "CV score:  0.609 \n",
      "\n",
      "Decision Stump Accuracy:  0.555\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.589 \n",
      "\n",
      "Decision Stump Accuracy:  0.51\n",
      "StratifiedKFold Mean test accuracy: 59.200%\n",
      "\n",
      "CV score:  0.5919999999999999 \n",
      "\n",
      "Decision Stump Accuracy:  0.55\n",
      "StratifiedKFold Mean test accuracy: 58.900%\n",
      "\n",
      "CV score:  0.5890000000000001 \n",
      "\n",
      "[0.635, 0.58, 0.575, 0.62, 0.64, 0.595, 0.64, 0.555, 0.51, 0.55]\n",
      "Decision Stump mean score for the dataset is:  0.59\n"
     ]
    }
   ],
   "source": [
    "decisionStump = DecisionTreeClassifier(max_depth=1,random_state = seed)\n",
    "\n",
    "DecisionStumpCVMeans = []\n",
    "DecisionStumpMeans6 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    multNoise = np.random.normal(1, 0.2, np.shape(X_test4))\n",
    "\n",
    "    xTestMultiNoise = np.multiply(X_test4, multNoise)\n",
    "    \n",
    "    decisionStump = DecisionTreeClassifier(max_depth=1,random_state = testseed)\n",
    "    decisionStump.fit(X_train4, y_train4.ravel())\n",
    "    predicted = decisionStump.predict(xTestMultiNoise)\n",
    "    print(\"Decision Stump Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    DecisionStumpMeans6.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(decisionStump, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    DecisionStumpCVMeans.append(score)\n",
    "    \n",
    "print(DecisionStumpMeans6)\n",
    "\n",
    "DecisionStumpScore = np.mean(DecisionStumpMeans6)\n",
    "\n",
    "DecisionStumpframe = pd.DataFrame(DecisionStumpMeans6)\n",
    "DecisionStumpSD = DecisionStumpframe.std()\n",
    "\n",
    "\n",
    "print(\"Decision Stump mean score for the dataset is: \", DecisionStumpScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90e3ccf7-a5df-4bca-b45f-4c2e09d3f22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006333807744188041\n",
      "Pruned Decision Tree Accuracy:  0.675\n",
      "StratifiedKFold Mean test accuracy: 66.800%\n",
      "\n",
      "CV score:  0.668 \n",
      "\n",
      "0.004683677477275278\n",
      "Pruned Decision Tree Accuracy:  0.59\n",
      "StratifiedKFold Mean test accuracy: 66.500%\n",
      "\n",
      "CV score:  0.6649999999999999 \n",
      "\n",
      "0.0035217391304347805\n",
      "Pruned Decision Tree Accuracy:  0.62\n",
      "StratifiedKFold Mean test accuracy: 66.400%\n",
      "\n",
      "CV score:  0.664 \n",
      "\n",
      "0.007057069744221267\n",
      "Pruned Decision Tree Accuracy:  0.665\n",
      "StratifiedKFold Mean test accuracy: 64.900%\n",
      "\n",
      "CV score:  0.649 \n",
      "\n",
      "0.0013888888888888887\n",
      "Pruned Decision Tree Accuracy:  0.59\n",
      "StratifiedKFold Mean test accuracy: 62.600%\n",
      "\n",
      "CV score:  0.626 \n",
      "\n",
      "0.0023809523809523807\n",
      "Pruned Decision Tree Accuracy:  0.67\n",
      "StratifiedKFold Mean test accuracy: 65.200%\n",
      "\n",
      "CV score:  0.6519999999999999 \n",
      "\n",
      "0.00677668818853009\n",
      "Pruned Decision Tree Accuracy:  0.695\n",
      "StratifiedKFold Mean test accuracy: 67.800%\n",
      "\n",
      "CV score:  0.678 \n",
      "\n",
      "0.0024999999999999996\n",
      "Pruned Decision Tree Accuracy:  0.63\n",
      "StratifiedKFold Mean test accuracy: 64.000%\n",
      "\n",
      "CV score:  0.64 \n",
      "\n",
      "0.0038744212962962977\n",
      "Pruned Decision Tree Accuracy:  0.635\n",
      "StratifiedKFold Mean test accuracy: 67.400%\n",
      "\n",
      "CV score:  0.674 \n",
      "\n",
      "0.005665811567164179\n",
      "Pruned Decision Tree Accuracy:  0.57\n",
      "StratifiedKFold Mean test accuracy: 68.400%\n",
      "\n",
      "CV score:  0.6839999999999999 \n",
      "\n",
      "[0.675, 0.59, 0.62, 0.665, 0.59, 0.67, 0.695, 0.63, 0.635, 0.57]\n",
      "Pruned Decision Tree mean score for the dataset is:  0.634\n"
     ]
    }
   ],
   "source": [
    "prunedDecisionTree = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "prunedDecisionTreeCVMeans = []\n",
    "prunedDecisionTreeMeans6 = []\n",
    "\n",
    "testseed = 333\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    X_train4, X_test4, y_train4, y_test4 = train_test_split(newX, y, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    multNoise = np.random.normal(1, 0.2, np.shape(X_test4))\n",
    "\n",
    "    xTestMultiNoise = np.multiply(X_test4, multNoise)\n",
    "        \n",
    "    X_train4VAL, X_val, y_train4VAL, y_val = train_test_split(xMultiNoise, y_train4, test_size=0.2, random_state = testseed)\n",
    "    \n",
    "    treePath = DecisionTreeClassifier(random_state=testseed).cost_complexity_pruning_path(X_train4VAL, y_train4VAL)\n",
    "    \n",
    "    accuracyScores = []\n",
    "    \n",
    "    for i in treePath.ccp_alphas:\n",
    "        accuracyScores.append(DecisionTreeClassifier(ccp_alpha=i, random_state=testseed).fit(X_train4VAL, y_train4VAL).score(X_val, y_val))\n",
    "        \n",
    "    bestAlphaValue = treePath.ccp_alphas[np.argmax(accuracyScores)]\n",
    "    print(bestAlphaValue)\n",
    "    \n",
    "    prunedDecisionTree = DecisionTreeClassifier(ccp_alpha=bestAlphaValue, random_state = testseed)\n",
    "    prunedDecisionTree.fit(X_train4, y_train4.ravel())\n",
    "    predicted = prunedDecisionTree.predict(xTestMultiNoise)\n",
    "    print(\"Pruned Decision Tree Accuracy: \", accuracy_score(y_test4, predicted))\n",
    "    prunedDecisionTreeMeans6.append(accuracy_score(y_test4, predicted))\n",
    "    \n",
    "    multi = StratifiedKFold(n_splits = 5, shuffle = True, random_state = testseed)\n",
    "    scoreList = cross_val_score(prunedDecisionTree, newX, y.ravel(), cv=multi)\n",
    "    print(f\"StratifiedKFold Mean test accuracy: {np.mean(scoreList)*100:.3f}%\\n\")\n",
    "    score = np.mean(scoreList)\n",
    "    print(\"CV score: \",score,'\\n')\n",
    "    testseed += 50\n",
    "    prunedDecisionTreeCVMeans.append(score)\n",
    "    \n",
    "print(prunedDecisionTreeMeans6)\n",
    "\n",
    "prunedDecisionTreeScore = np.mean(prunedDecisionTreeMeans6)\n",
    "\n",
    "prunedDecisionTreeframe = pd.DataFrame(prunedDecisionTreeMeans6)\n",
    "prunedDecisionTreeSD = prunedDecisionTreeframe.std()\n",
    "\n",
    "\n",
    "print(\"Pruned Decision Tree mean score for the dataset is: \", prunedDecisionTreeScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad7e8a83-68d2-40aa-af35-535e673d4cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Decision Tree  Random Forest  Decision Stump  Pruned Decision Tree\n",
      "0          0.680          0.740           0.635                 0.675\n",
      "1          0.600          0.700           0.580                 0.590\n",
      "2          0.590          0.725           0.575                 0.620\n",
      "3          0.575          0.660           0.620                 0.665\n",
      "4          0.575          0.735           0.640                 0.590\n",
      "5          0.650          0.720           0.595                 0.670\n",
      "6          0.645          0.680           0.640                 0.695\n",
      "7          0.595          0.660           0.555                 0.630\n",
      "8          0.640          0.690           0.510                 0.635\n",
      "9          0.590          0.685           0.550                 0.570\n",
      "RankResult(rankdf=\n",
      "                      meanrank    mean       std  ci_lower  ci_upper  \\\n",
      "Random Forest              1.2  0.6995  0.029387  0.676359  0.722641   \n",
      "Pruned Decision Tree       2.3  0.6340  0.041952  0.610859  0.657141   \n",
      "Decision Tree              2.8  0.6140  0.036576  0.590859  0.637141   \n",
      "Decision Stump             3.7  0.5900  0.044096  0.566859  0.613141   \n",
      "\n",
      "                     effect_size   magnitude  \n",
      "Random Forest                0.0  negligible  \n",
      "Pruned Decision Tree     1.80845       large  \n",
      "Decision Tree           2.577109       large  \n",
      "Decision Stump           2.92231       large  \n",
      "pvalue=2.700663194244113e-07\n",
      "cd=None\n",
      "omnibus=anova\n",
      "posthoc=tukeyhsd\n",
      "all_normal=True\n",
      "pvals_shapiro=[0.13707900047302246, 0.4254987835884094, 0.4325263798236847, 0.6466541290283203]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.6634743151226452\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=10\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n",
      "The statistical analysis was conducted for 4 populations with 10 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=0.137). Therefore, we assume that all populations are normal.\n",
      "We applied Bartlett's test for homogeneity and failed to reject the null hypothesis (p=0.663) that the data is homoscedastic. Thus, we assume that our data is homoscedastic.\n",
      "Because we have more than two populations and all populations are normal and homoscedastic, we use repeated measures ANOVA as omnibus test to determine if there are any significant differences between the mean values of the populations. If the results of the ANOVA test are significant, we use the post-hoc Tukey HSD test to infer which differences are significant. We report the mean value (M) and the standard deviation (SD) for each population. Populations are significantly different if their confidence intervals are not overlapping.\n",
      "We reject the null hypothesis (p=0.000) of the repeated measures ANOVA that there is a difference between the mean values of the populations Random Forest (M=0.700+-0.023, SD=0.029), Pruned Decision Tree (M=0.634+-0.023, SD=0.042), Decision Tree (M=0.614+-0.023, SD=0.037), and Decision Stump (M=0.590+-0.023, SD=0.044). Therefore, we assume that there is a statistically significant difference between the mean values of the populations.\n",
      "Based post-hoc Tukey HSD test, we assume that there are no significant differences within the following groups: Pruned Decision Tree and Decision Tree. All other differences are significant.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jordan\\.conda\\envs\\venv\\lib\\site-packages\\statsmodels\\sandbox\\stats\\multicomp.py:775: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax1.set_yticklabels(np.insert(self.groupsunique.astype(str), 0, ''))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'95.0% Confidence Intervals of the Mean'}>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_means = {\n",
    "    'Decision Tree':DecisionTreeMeans6,\n",
    "    'Random Forest':RandomForestMeans6,\n",
    "    'Decision Stump':DecisionStumpMeans6,\n",
    "    'Pruned Decision Tree':prunedDecisionTreeMeans6\n",
    "}\n",
    "\n",
    "data = pd.DataFrame (model_means, columns = ['Decision Tree', 'Random Forest', 'Decision Stump', 'Pruned Decision Tree'])\n",
    "print(data)\n",
    "results = autorank(data, verbose=False)\n",
    "print(results)\n",
    "create_report(results)\n",
    "plot_stats(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537cf06-0388-4fb1-9614-f5a16aca9e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
