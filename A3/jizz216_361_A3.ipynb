{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Kaggle Score: 88%\n",
    "Final Kaggle Score: 80.33%\n",
    "\n",
    "To start, I have to make it clear that due to having no Cross Validation code, I don't have valuable statistics to demonstrate the range of my models performance, but as it's well below 90% it's quite clear that my model is not performing the way it should be anyway.\n",
    "\n",
    "In terms of pre-processing, once the training data is read, I made sure to do the standard word cleaning procedures like making sure all words contain only lowercase letters, remove any punctuation to avoid situations like \"test\" and \"test.\" being added to the Bag of Words separately. Once that was done, while scanning each abstract and appending its contents to a dictionary to send to my runNB function, I also removed a list of common stop-words (these were taken from a list of supposed words google used to filter in their search engine algorithm). Something I could've implemented in my pre-processing was 'stemming': I noticed that often times in my bag of words, I'd come across words like 'gene'/'genes' or 'sequence'/'sequences'. In my model, these would be stored as seperate words, but they should've been stored as the same word by only keeping the root word (in these examples removing the 's' at the end, for other cases it could be that we remove 'ed', 'ing' etc. \n",
    "\n",
    "Once the dictionary is appended to the runNB function, I've scanned each paragraph and taken the relevant information (total words, total words per class, unique words per class etc) for calculating priors and likelihood. From there, the counts of how many times a word appears per class were taken, and these counts + the words found in each class were zipped together into a dictionary, creating my bag of words. Once the bag of words was created, I've gone through every count value and divided it by the total number of words in the class, giving word likelihood values. Finally, these numbers were logged to prevent underflow, as I knew looking at the training & test data, that the model would be reading a lot of words and that some of these values might be lost to underflow. By logging them, python doesn't round them to 0, losing valuable information for rarely occuring words. After this, priors were calculated (and also logged, not to prevent underflow but for consistency in the method). Lastly, the prior values were added to my bag of words so that the next function, makePrediction, had all necessary information to classify each instance. \n",
    "\n",
    "Finally I created a list of 4 0's, and after reading the test file I ran each row of the test file through makePrediction, which examined every word against the bag of words, and appended each classes likelihood to classLikeliness for final scoring. The Naive Bayes calculation essentially happens at this step, with these values all being added together as Log(A * B) is equivalent to Log(A) + Log(B) via log properties. Then, to actually choose the classifier for each row, I've taken the min() of classLikeliness. This is actually weird because I know the Naive Bayes is supposed to take the max() value, which would make sense as the likelihoods for each word in classes where they appear often were way smaller than classes where they were sparse, therefore the most likely class SHOULD be the smallest negative number. The errors in my algorithms logic, (like in this case) are likely the cause for the subpar classification accuracy, something I'll have to examine closely in the future. \n",
    "\n",
    "In terms of extensions, while I didn't get to implement any, I was deciding between using TF-IDF, and N-Grams. For N-Grams, I was considering this extension as I noticed that a lot of the paragraphs that were being read into the model had a lot of similar words between eachother. Therefore, by implementing either bi-grams or tri-grams into my model, I believe it would've helped contextualize what data was being stored into a way that would've been more predictive of each class. While a problem with the N-Grams extension is that it requires a lot of training data to get more examples (so that each bi/tri-gram isnt stored in the BoW with a low likelihood count), I dont think that would've been an issue in the case of the data provided for this assignment. One issue I did forsee happening however, was that implementation of this extension might've increased runtime, which while not a problem in terms of classification accuracy, would've been worse for quality of life.\n",
    "\n",
    "Therefore, I think in the end I would've chosen to go with TF-IDF. As I didnt remove the top1000 words in my model, implementing TF-IDF would've helped weight the rarer, more indicitive words/features higher in the model, possibly leading to a solid gain in accuracy. I noticed when working with the data that words like 'gene', 'sequence' and many other biology related words were appearing a lot. as they were typically the highest counted words across all of the classifiers, their inclusion in the calculations for P(C) would've been more of a hinderance than a benefit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##FILE HANDLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ldct8lRgNGYW",
    "outputId": "e82fb637-ec46-4ec6-91d0-5d4047b73473"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def readFile(filename):\n",
    "    with open(filename, 'r') as theFile:\n",
    "        row = csv.reader(theFile, delimiter=',')\n",
    "        next(row)\n",
    "        data = [data for data in row]\n",
    "        \n",
    "    return data\n",
    "\n",
    "def getTestData(filename):\n",
    "    \n",
    "    with open(filename, 'r') as theFile:\n",
    "        file = csv.reader(theFile, delimiter=',')\n",
    "        \n",
    "        #cleaning the input data for better readability from the model\n",
    "        allRows = [row[1].translate(str.maketrans('','',string.punctuation)).lower() for row in file][1:]\n",
    "    \n",
    "    for i in range(len(allRows)):\n",
    "        allRows[i]=allRows[i].split()\n",
    "        \n",
    "    return allRows\n",
    "\n",
    "\n",
    "def dataToDict(fileData):\n",
    "\n",
    "    #Stop words to ignore, taken from the list of popular stopwords google used to use in their search algorithm\n",
    "    uselessWords = ['the','i', 'a', 'about', 'an', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'how', 'in', 'is'\n",
    "                   'it', 'of', 'on', 'or', 'that', 'the', 'this', 'to', 'was', 'what', 'when', 'where', 'who',\n",
    "                    'will', 'with']\n",
    "\n",
    "    wordDict={}\n",
    "\n",
    "    for para in fileData[:50]:#\n",
    "        target = para[1]\n",
    "        paragraph = para[2].translate(str.maketrans('','',string.punctuation)).lower()\n",
    "\n",
    "        splitPara = paragraph.split()\n",
    "        cleanPara =[]\n",
    "\n",
    "        if target not in wordDict.keys():\n",
    "            wordDict[target] = []\n",
    "            wordDict[target].append(cleanPara)\n",
    "        else:\n",
    "            wordDict[target].append(cleanPara)\n",
    "\n",
    "        for word in splitPara:\n",
    "            if word not in uselessWords:\n",
    "                cleanPara.append(word)\n",
    "                \n",
    "    return wordDict\n",
    "\n",
    "\n",
    "def output(results): \n",
    "    int = 0\n",
    "\n",
    "    file = open('jizz216.csv', 'a') \n",
    "    file.write('id,class'+'\\n')\n",
    "    \n",
    "    for target in results: \n",
    "        int += 1\n",
    "        file.write(str(int)+','+target+'\\n')  \n",
    "\n",
    "    file.close() \n",
    "\n",
    "                \n",
    "Array = np.asarray(readFile('trg.csv'))\n",
    "forModel = dataToDict(Array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##NAIVE BAYES CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lW2llZKPEoKL",
    "outputId": "59167a78-00b3-4784-da55-940661c5ec85"
   },
   "outputs": [],
   "source": [
    "def runNB(inputDict):\n",
    "    \n",
    "    countDict = {}\n",
    "    \n",
    "    allWords = []\n",
    "    \n",
    "    classTotals = []\n",
    "\n",
    "    #look at each classifier, and each paragraph classified under this classifier\n",
    "    for target in inputDict: \n",
    "        \n",
    "        classWordsDuplicate = []\n",
    "        wordCount = []\n",
    "\n",
    "        #finding the total words in each class\n",
    "        for para in inputDict[target]: \n",
    "            for word in para: \n",
    "                classWordsDuplicate.append(word)\n",
    "                    \n",
    "        #getting the list of unique words from the total words list\n",
    "        uniqueWords = np.unique(classWordsDuplicate)\n",
    "        \n",
    "        #adding unique words to the vocab\n",
    "        allWords.extend(uniqueWords)\n",
    "        \n",
    "        #total word value for each class\n",
    "        classWordAmount = len(classWordsDuplicate)\n",
    "        \n",
    "        #getting the count for each unique word, adding 1 to avoid multiplication by 0\n",
    "        for word in uniqueWords: \n",
    "            wordAmount = classWordsDuplicate.count(word) + 1\n",
    "            wordCount.append(wordAmount)\n",
    "        \n",
    "        #taking class unique words & their word counts to create the Bag of Words\n",
    "        classWordCounts = dict(zip(uniqueWords, wordCount)) \n",
    "        \n",
    "        #taking the dictionary we just created, and assigning it to its respective class\n",
    "        if target not in countDict.keys(): \n",
    "            countDict[target] = classWordCounts \n",
    "\n",
    "        #saving the word count for each class to calculate denominator for NB later\n",
    "        classTotals.append(classWordAmount) \n",
    "\n",
    "    #beginning the prior calculation for each class\n",
    "    totalParagraphs = 0\n",
    "    classParaCounts = []\n",
    "    priorList = []\n",
    "    \n",
    "    #getting the class occurence count and total row amount\n",
    "    for key in inputDict:\n",
    "        classParaCounts.append(len(inputDict[key]))\n",
    "        totalParagraphs += len(inputDict[key])\n",
    "    \n",
    "    #calculating the priors, using log as we will log the feature conditionals as well\n",
    "    for val in classParaCounts:\n",
    "        priorList.append(math.log(val/totalParagraphs))\n",
    "        \n",
    "    outputDict = {}\n",
    "   \n",
    "    #getting the count of all words in the input data\n",
    "    wordAmountConstant = len(allWords)\n",
    "    \n",
    "    #saving the calculated denominator values\n",
    "    denomValues = []\n",
    "    for val in classTotals:\n",
    "        denomValues.append(val+wordAmountConstant)\n",
    "\n",
    "    \n",
    "    #preparing our final bag of words to send to predictive function for classification, first adding priors\n",
    "    counter = 0\n",
    "    for key in inputDict:\n",
    "        if key not in outputDict:\n",
    "            outputDict[key] = {'Prior'+key: priorList[counter]} #math.log()\n",
    "        counter += 1\n",
    "    \n",
    "    #then merging the output dictionary with our priors with the bag of words\n",
    "    counter = 0\n",
    "    for target,classDict in countDict.items():\n",
    "        for key,occurs in classDict.items():\n",
    "            countDict[target][key] = math.log(occurs/denomValues[counter])\n",
    "        \n",
    "        for key, occurs in classDict.items():\n",
    "            outputDict[target][key] = occurs\n",
    "            \n",
    "        counter += 1\n",
    "\n",
    "    return outputDict\n",
    "\n",
    "\n",
    "readyToPredict = runNB(forModel)\n",
    "\n",
    "testData = getTestData(\"tst.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##MAKING PREDICTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGqKPAu5tOuG",
    "outputId": "df1e12fa-f951-4538-be87-fee7dd5cdee9"
   },
   "outputs": [],
   "source": [
    "def makePrediction(toBePredicted, bagOfWords):\n",
    "\n",
    "    uselessWords = ['the','i', 'a', 'about', 'an', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'how', 'in', 'is'\n",
    "               'it', 'of', 'on', 'or', 'that', 'the', 'this', 'to', 'was', 'what', 'when', 'where', 'who',\n",
    "                'will', 'with']\n",
    "    \n",
    "    classLikeliness = [0  ,0  ,0  ,0 ]\n",
    "    targetName = ['A','B','E','V']\n",
    "    priors = []\n",
    "    \n",
    "    #adding the priors to a local priors list\n",
    "    for target, probabilityDict in bagOfWords.items():\n",
    "        for key, val in probabilityDict.items():\n",
    "            if key == 'PriorA':\n",
    "                priors.append(probabilityDict['PriorA'])\n",
    "            elif key == 'PriorB':\n",
    "                priors.append(probabilityDict['PriorB'])\n",
    "            elif key == 'PriorE':\n",
    "                priors.append(probabilityDict['PriorE'])\n",
    "            elif key == 'PriorV':\n",
    "                priors.append(probabilityDict['PriorV'])\n",
    "\n",
    "    #looking at every word in the paragraph, and based on its likeliness, adding its score to each classifier respectively\n",
    "    for word in toBePredicted:\n",
    "        if word not in uselessWords:\n",
    "            for target, probabilityDict in bagOfWords.items():\n",
    "                for key, val in probabilityDict.items():\n",
    "                    if word == key:\n",
    "                        if target == 'A':\n",
    "                            classLikeliness[0] += val\n",
    "                        if target == 'B':\n",
    "                            classLikeliness[1] += val\n",
    "                        if target == 'E':\n",
    "                            classLikeliness[2] += val\n",
    "                        if target == 'V':\n",
    "                            classLikeliness[3] += val\n",
    "\n",
    "    #adding the logged priors to each classes likeliness score\n",
    "    for i in range(len(priors)):\n",
    "        classLikeliness[i] += priors[i]\n",
    "\n",
    "    prediction = targetName[classLikeliness.index(min(classLikeliness))]\n",
    "    \n",
    "    return(prediction) # for every paragraph we input, spit out either A B E or V\n",
    "\n",
    "finalPredictions = []\n",
    "\n",
    "#looking through every row of the test data, and predicting its class\n",
    "for row in testData:\n",
    "    finalPredictions.append(makePrediction(row, readyToPredict))\n",
    "\n",
    "\n",
    "output(finalPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "762A3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
